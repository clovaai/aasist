{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffc5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "from shutil import copy\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "from data_utils import (Dataset_ASVspoof2019_train,\n",
    "                        Dataset_ASVspoof2019_devNeval, genSpoof_list_prevDbs, genSpoof_list,\n",
    "                        Dataset_train_prevDbs, Dataset_PrevDbs, Dataset_cs2, Dataset_train_cs2)\n",
    "from evaluation import calculate_tDCF_EER\n",
    "from utils import create_optimizer, seed_worker, set_seed, str_to_bool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2ffeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"database_path\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/combinedSet2\",\n",
    "#     \"asv_score_path\": \"ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.eval.gi.trl.scores.txt\",\n",
    "    \"model_path\": \"./models/weights/AASIST-L.pth\",\n",
    "    \"batch_size\": 24,\n",
    "    \"num_epochs\": 100,\n",
    "    \"loss\": \"CCE\",\n",
    "    \"track\": \"LA\",\n",
    "    \"eval_all_best\": \"True\",\n",
    "    \"eval_output\": \"eval_scores_cs2_cs2.txt\",\n",
    "    \"cudnn_deterministic_toggle\": \"True\",\n",
    "    \"cudnn_benchmark_toggle\": \"False\",\n",
    "    \"model_config\": {\n",
    "        \"architecture\": \"AASIST\",\n",
    "        \"nb_samp\": 64600,\n",
    "        \"first_conv\": 128,\n",
    "        \"filts\": [70, [1, 32], [32, 32], [32, 24], [24, 24]],\n",
    "        \"gat_dims\": [24, 32],\n",
    "        \"pool_ratios\": [0.4, 0.5, 0.7, 0.5],\n",
    "        \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n",
    "    },\n",
    "    \"optim_config\": {\n",
    "        \"optimizer\": \"adam\", \n",
    "        \"amsgrad\": \"False\",\n",
    "        \"base_lr\": 0.0001,\n",
    "        \"lr_min\": 0.000005,\n",
    "        \"betas\": [0.9, 0.999],\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"scheduler\": \"cosine\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9257394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = config[\"model_config\"]\n",
    "optim_config = config[\"optim_config\"]\n",
    "optim_config[\"epochs\"] = config[\"num_epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a203b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"eval_all_best\" not in config:\n",
    "    config[\"eval_all_best\"] = \"True\"\n",
    "if \"freq_aug\" not in config:\n",
    "    config[\"freq_aug\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72dd136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1234, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0e5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random \n",
    " \n",
    "# cs1 = open(\"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/combined_train_protocol.txt\", 'r')\n",
    "# reduced_trainset8 = open(\"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/reduced_trainset8.txt\", 'r')\n",
    "# reduced_devSet = open(\"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/reduced_devset.txt\", 'r')\n",
    "# newTrain = open('./protocols/combinedSet2_train.txt', 'w')\n",
    "# newDev = open('./protocols/combinedSet2_dev.txt', 'w')\n",
    "\n",
    "# # print(len(cs1.readlines()))\n",
    "# # print(len(reduced_trainset8.readlines()))\n",
    "# # print(len(reduced_devSet.readlines()))\n",
    "\n",
    "# for line in reduced_trainset8:\n",
    "#     _, name, _, _, label = line.split(\" \")\n",
    "#     newTrain.write('- ' + name+'.flac' + ' - - ' + label)\n",
    "# for line in reduced_devSet:\n",
    "#     _, name, _, _, label = line.split(\" \")\n",
    "#     newDev.write('- ' + name +'.flac' + ' - - ' + label)\n",
    "# for line in cs1:\n",
    "#     name, label = line.split(\" \")\n",
    "# #     print('- ' + name + ' - - ' + label)\n",
    "#     r = random.random()\n",
    "#     if r < 0.90:\n",
    "#         newTrain.write('- ' + name + '.wav' + ' - - ' + label)\n",
    "#     else:\n",
    "#         newDev.write('- ' + name + '.wav' + ' - - ' + label)\n",
    "    \n",
    "# cs1.close()\n",
    "# reduced_trainset8.close()\n",
    "# reduced_devSet.close()\n",
    "# newTrain.close()\n",
    "# newDev.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d9590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir './combinedSet2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bedcc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# asv_train_path = '/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_train/flac/'\n",
    "# asv_dev_path = '/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_dev/flac/'\n",
    "\n",
    "# cs1_train_path = '/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/combined/Train/'\n",
    "\n",
    "# destination_path = './combinedSet2/'\n",
    "\n",
    "# trainProtocol = open('./protocols/combinedSet2_train.txt', 'r')\n",
    "# for line in trainProtocol:\n",
    "#     _, name, _, _, _ = line.split(\" \")\n",
    "#     source_file = asv_train_path + name + '.flac'\n",
    "#     destination_file = destination_path + name + '.flac'\n",
    "#     if(os.path.isfile(source_file)):\n",
    "#         shutil.copy(source_file, destination_file)\n",
    "#     source_file = cs1_train_path + name + '.wav'\n",
    "#     destination_file = destination_path + name + '.wav'\n",
    "#     if(os.path.isfile(source_file)):\n",
    "#         shutil.copy(source_file, destination_file)\n",
    "    \n",
    "# devProtocol = open('./protocols/combinedSet2_dev.txt', 'r')\n",
    "# for line in devProtocol:\n",
    "#     _, name, _, _, _ = line.split(\" \")\n",
    "#     source_file = asv_dev_path + name + '.flac'\n",
    "#     destination_file = destination_path + name + '.flac'\n",
    "#     if(os.path.isfile(source_file)):\n",
    "#         shutil.copy(source_file, destination_file)\n",
    "#     source_file = cs1_train_path + name + '.wav'\n",
    "#     destination_file = destination_path + name + '.wav'\n",
    "#     if(os.path.isfile(source_file)):\n",
    "#         shutil.copy(source_file, destination_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aff37b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/combinedSet2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"database_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8b66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('./exp_result')\n",
    "database_path = Path(config[\"database_path\"])\n",
    "dev_trial_path = Path('./protocols/combinedSet2_dev.txt')\n",
    "# eval_trial_path = Path('/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46dae22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model related paths\n",
    "model_tag = \"{}_{}_ep{}_bs{}\".format(\n",
    "    'CS2',\n",
    "    'AASIST-L',\n",
    "    config[\"num_epochs\"], config[\"batch_size\"])\n",
    "model_tag = output_dir / model_tag\n",
    "model_save_path = model_tag / \"weights\"\n",
    "eval_score_path = model_tag / config[\"eval_output\"]\n",
    "writer = SummaryWriter(model_tag)\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40eb6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_config: Dict, device: torch.device):\n",
    "    \"\"\"Define DNN model architecture\"\"\"\n",
    "    module = import_module(\"models.{}\".format(model_config[\"architecture\"]))\n",
    "    _model = getattr(module, \"Model\")\n",
    "    model = _model(model_config).to(device)\n",
    "    nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "    print(\"no. model params:{}\".format(nb_params))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "686ab894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "no. model params:85306\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: {}\".format(device))\n",
    "if device == \"cpu\":\n",
    "    raise ValueError(\"GPU not detected!\")\n",
    "\n",
    "# define model architecture\n",
    "model = get_model(model_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3109f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/combinedSet2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f42be54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. training files: 3518\n",
      "no. validation files: 1352\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Make PyTorch DataLoaders for train / developement / evaluation\"\"\"\n",
    "\n",
    "trn_database_path = database_path \n",
    "dev_database_path = database_path \n",
    "\n",
    "trn_list_path = Path('./protocols/combinedSet2_train.txt')\n",
    "dev_trial_path = './protocols/combinedSet2_dev.txt'\n",
    "d_label_trn, file_train = genSpoof_list(dir_meta=trn_list_path,\n",
    "                                        is_train=True,\n",
    "                                        is_eval=False)\n",
    "print(\"no. training files:\", len(file_train))\n",
    "\n",
    "train_set = Dataset_train_cs2(list_IDs=file_train,\n",
    "                                       labels=d_label_trn,\n",
    "                                       base_dir=trn_database_path)\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(1234)\n",
    "trn_loader = DataLoader(train_set,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        pin_memory=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=gen)\n",
    "\n",
    "_, file_dev = genSpoof_list(dir_meta=dev_trial_path,\n",
    "                            is_train=False,\n",
    "                            is_eval=False)\n",
    "print(\"no. validation files:\", len(file_dev))\n",
    "\n",
    "dev_set = Dataset_cs2(list_IDs=file_dev,\n",
    "                                        base_dir=dev_database_path)\n",
    "dev_loader = DataLoader(dev_set,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ad5843e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get optimizer and scheduler\n",
    "optim_config[\"steps_per_epoch\"] = len(trn_loader)\n",
    "optimizer, scheduler = create_optimizer(model.parameters(), optim_config)\n",
    "optimizer_swa = SWA(optimizer)\n",
    "\n",
    "best_dev_eer = 1.\n",
    "best_eval_eer = 100.\n",
    "best_dev_tdcf = 0.05\n",
    "best_eval_tdcf = 1.\n",
    "n_swa_update = 0  # number of snapshots of model to use in SWA\n",
    "f_log = open(model_tag / \"metric_log.txt\", \"a\")\n",
    "f_log.write(\"=\" * 5 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dda8ab93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('exp_result/CS2_AASIST-L_ep100_bs24')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45246d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory for metric logging\n",
    "metric_path = model_tag / \"metrics\"\n",
    "os.makedirs(metric_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f653c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            _, utt_id, _, _, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} \\n\".format(utt_id, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    trn_loader: DataLoader,\n",
    "    model,\n",
    "    optim: Union[torch.optim.SGD, torch.optim.Adam],\n",
    "    device: torch.device,\n",
    "    scheduler: torch.optim.lr_scheduler,\n",
    "    config: argparse.Namespace):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    running_loss = 0\n",
    "    num_total = 0.0\n",
    "    ii = 0\n",
    "    model.train()\n",
    "\n",
    "    # set objective (Loss) functions\n",
    "    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    for batch_x, batch_y in trn_loader:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        ii += 1\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        _, batch_out = model(batch_x, Freq_aug=str_to_bool(config[\"freq_aug\"]))\n",
    "        batch_loss = criterion(batch_out, batch_y)\n",
    "        running_loss += batch_loss.item() * batch_size\n",
    "        optim.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if config[\"optim_config\"][\"scheduler\"] in [\"cosine\", \"keras_decay\"]:\n",
    "            scheduler.step()\n",
    "        elif scheduler is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"scheduler error, got:{}\".format(scheduler))\n",
    "\n",
    "    running_loss /= num_total\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c70ea672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluation import compute_eer\n",
    "def getEER(score_path):\n",
    "    cm_data = np.genfromtxt(score_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 1]\n",
    "    cm_scores = cm_data[:, 2].astype(float)\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "    return eer_cm * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0945d498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training epoch000\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.59089, dev_eer: 48.311\n",
      "Start training epoch001\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.51065, dev_eer: 43.649\n",
      "Start training epoch002\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.49151, dev_eer: 42.317\n",
      "Start training epoch003\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.46842, dev_eer: 36.061\n",
      "Start training epoch004\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.44362, dev_eer: 33.254\n",
      "Start training epoch005\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.42425, dev_eer: 31.304\n",
      "Start training epoch006\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.41599, dev_eer: 26.689\n",
      "Start training epoch007\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.39476, dev_eer: 24.643\n",
      "Start training epoch008\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.37741, dev_eer: 26.070\n",
      "Start training epoch009\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.33821, dev_eer: 21.051\n",
      "Start training epoch010\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.31682, dev_eer: 23.359\n",
      "Start training epoch011\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.29885, dev_eer: 19.672\n",
      "Start training epoch012\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.27835, dev_eer: 21.313\n",
      "Start training epoch013\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.24982, dev_eer: 16.603\n",
      "Start training epoch014\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.24983, dev_eer: 16.698\n",
      "Start training epoch015\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.22385, dev_eer: 14.748\n",
      "Start training epoch016\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.21133, dev_eer: 15.319\n",
      "Start training epoch017\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.20683, dev_eer: 13.321\n",
      "Start training epoch018\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.18334, dev_eer: 16.746\n",
      "Start training epoch019\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.18317, dev_eer: 11.370\n",
      "Start training epoch020\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.16746, dev_eer: 12.607\n",
      "Start training epoch021\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.16686, dev_eer: 10.038\n",
      "Start training epoch022\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.14851, dev_eer: 9.681\n",
      "Start training epoch023\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.14383, dev_eer: 9.015\n",
      "Start training epoch024\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.12402, dev_eer: 9.063\n",
      "Start training epoch025\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.12690, dev_eer: 8.302\n",
      "Start training epoch026\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.11632, dev_eer: 9.015\n",
      "Start training epoch027\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.10005, dev_eer: 9.324\n",
      "Start training epoch028\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.10590, dev_eer: 8.968\n",
      "Start training epoch029\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.09658, dev_eer: 9.015\n",
      "Start training epoch030\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.09569, dev_eer: 8.611\n",
      "Start training epoch031\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.10125, dev_eer: 8.706\n",
      "Start training epoch032\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.08516, dev_eer: 8.706\n",
      "Start training epoch033\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.07632, dev_eer: 9.729\n",
      "Start training epoch034\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.07979, dev_eer: 7.326\n",
      "Start training epoch035\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06642, dev_eer: 6.351\n",
      "Start training epoch036\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.08436, dev_eer: 7.588\n",
      "Start training epoch037\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.08080, dev_eer: 7.683\n",
      "Start training epoch038\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.07046, dev_eer: 8.349\n",
      "Start training epoch039\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06791, dev_eer: 7.017\n",
      "Start training epoch040\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06600, dev_eer: 8.658\n",
      "Start training epoch041\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.07575, dev_eer: 7.326\n",
      "Start training epoch042\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06504, dev_eer: 6.351\n",
      "Start training epoch043\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06231, dev_eer: 10.347\n",
      "Start training epoch044\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04931, dev_eer: 6.351\n",
      "Start training epoch045\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.05093, dev_eer: 5.685\n",
      "Start training epoch046\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06226, dev_eer: 9.634\n",
      "Start training epoch047\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.05620, dev_eer: 8.349\n",
      "Start training epoch048\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.07759, dev_eer: 7.326\n",
      "Start training epoch049\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.05108, dev_eer: 7.683\n",
      "Start training epoch050\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04785, dev_eer: 8.611\n",
      "Start training epoch051\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04318, dev_eer: 6.351\n",
      "Start training epoch052\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04321, dev_eer: 7.992\n",
      "Start training epoch053\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04223, dev_eer: 7.017\n",
      "Start training epoch054\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04406, dev_eer: 6.351\n",
      "Start training epoch055\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04764, dev_eer: 6.351\n",
      "Start training epoch056\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03889, dev_eer: 7.374\n",
      "Start training epoch057\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.05234, dev_eer: 7.017\n",
      "Start training epoch058\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03478, dev_eer: 7.588\n",
      "Start training epoch059\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02975, dev_eer: 7.326\n",
      "Start training epoch060\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03827, dev_eer: 6.708\n",
      "Start training epoch061\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03295, dev_eer: 6.351\n",
      "Start training epoch062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04638, dev_eer: 7.945\n",
      "Start training epoch063\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03937, dev_eer: 6.613\n",
      "Start training epoch064\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02975, dev_eer: 7.945\n",
      "Start training epoch065\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04327, dev_eer: 7.326\n",
      "Start training epoch066\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03829, dev_eer: 7.374\n",
      "Start training epoch067\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02906, dev_eer: 7.017\n",
      "Start training epoch068\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03651, dev_eer: 5.994\n",
      "Start training epoch069\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04304, dev_eer: 7.326\n",
      "Start training epoch070\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03020, dev_eer: 6.351\n",
      "Start training epoch071\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03107, dev_eer: 6.351\n",
      "Start training epoch072\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02468, dev_eer: 6.256\n",
      "Start training epoch073\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03454, dev_eer: 6.922\n",
      "Start training epoch074\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02443, dev_eer: 5.685\n",
      "Start training epoch075\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02765, dev_eer: 7.279\n",
      "Start training epoch076\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02829, dev_eer: 6.970\n",
      "Start training epoch077\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02266, dev_eer: 6.660\n",
      "Start training epoch078\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03045, dev_eer: 7.326\n",
      "Start training epoch079\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02007, dev_eer: 7.374\n",
      "Start training epoch080\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02729, dev_eer: 6.351\n",
      "Start training epoch081\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02698, dev_eer: 6.042\n",
      "Start training epoch082\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02853, dev_eer: 6.660\n",
      "Start training epoch083\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02500, dev_eer: 7.017\n",
      "Start training epoch084\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02690, dev_eer: 6.351\n",
      "Start training epoch085\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02455, dev_eer: 6.922\n",
      "Start training epoch086\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02565, dev_eer: 6.660\n",
      "Start training epoch087\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02917, dev_eer: 6.351\n",
      "Start training epoch088\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02202, dev_eer: 5.994\n",
      "Start training epoch089\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03054, dev_eer: 6.660\n",
      "Start training epoch090\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01849, dev_eer: 7.326\n",
      "Start training epoch091\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03017, dev_eer: 6.660\n",
      "Start training epoch092\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02292, dev_eer: 6.660\n",
      "Start training epoch093\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02063, dev_eer: 7.017\n",
      "Start training epoch094\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01684, dev_eer: 6.970\n",
      "Start training epoch095\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02131, dev_eer: 6.613\n",
      "Start training epoch096\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02667, dev_eer: 6.708\n",
      "Start training epoch097\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02304, dev_eer: 6.708\n",
      "Start training epoch098\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01952, dev_eer: 6.399\n",
      "Start training epoch099\n",
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02110, dev_eer: 7.017\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    print(\"Start training epoch{:03d}\".format(epoch))\n",
    "    running_loss = train_epoch(trn_loader, model, optimizer, device,\n",
    "                               scheduler, config)\n",
    "    produce_evaluation_file(dev_loader, model, device,\n",
    "                            metric_path/\"dev_score.txt\", dev_trial_path)\n",
    "    dev_eer = getEER(metric_path/\"dev_score.txt\")\n",
    "    print(\"DONE.\\nLoss:{:.5f}, dev_eer: {:.3f}\".format(\n",
    "        running_loss, dev_eer))\n",
    "    writer.add_scalar(\"loss\", running_loss, epoch)\n",
    "    writer.add_scalar(\"dev_eer\", dev_eer, epoch)\n",
    "\n",
    "    if best_dev_eer >= dev_eer:\n",
    "        print(\"best model find at epoch\", epoch)\n",
    "        best_dev_eer = dev_eer\n",
    "        torch.save(model.state_dict(),\n",
    "                   model_save_path / \"epoch_{}_{:03.3f}.pth\".format(epoch, dev_eer))\n",
    "\n",
    "        # do evaluation whenever best model is renewed\n",
    "        if str_to_bool(config[\"eval_all_best\"]):\n",
    "            produce_evaluation_file(eval_loader, model, device,\n",
    "                                    eval_score_path, eval_trial_path)\n",
    "            dev_eer = getEER(metric_path/\"dev_score.txt\")\n",
    "            eval_eer = getEER(eval_score_path)\n",
    "\n",
    "            log_text = \"epoch{:03d}, \".format(epoch)\n",
    "            if eval_eer < best_eval_eer:\n",
    "                log_text += \"best eer, {:.4f}%\".format(eval_eer)\n",
    "                best_eval_eer = eval_eer\n",
    "                torch.save(model.state_dict(),\n",
    "                           model_save_path / \"best.pth\")\n",
    "            if len(log_text) > 0:\n",
    "                print(log_text)\n",
    "                f_log.write(log_text + \"\\n\")\n",
    "\n",
    "        print(\"Saving epoch {} for swa\".format(epoch))\n",
    "        optimizer_swa.update_swa()\n",
    "        n_swa_update += 1\n",
    "    writer.add_scalar(\"best_dev_eer\", best_dev_eer, epoch)\n",
    "    writer.add_scalar(\"best_dev_tdcf\", best_dev_tdcf, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb5b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29c6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea7c5a77",
   "metadata": {},
   "source": [
    "# LJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1200fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/lj_train_protocol.txt\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/lj_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/LJ/train/\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/LJ/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "183cca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "lj_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e64093f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv_time): CONV()\n",
       "  (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.5, inplace=True)\n",
       "  (drop_way): Dropout(p=0.2, inplace=True)\n",
       "  (selu): SELU(inplace=True)\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (conv1): Conv2d(1, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(32, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (GAT_layer_S): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (GAT_layer_T): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST11): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_type2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (att_proj): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST12): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST21): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_type2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (att_proj): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST22): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (pool_S): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=24, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_T): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=24, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (out_layer): Linear(in_features=160, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "196a6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS2_AASIST-L_ep100_bs24/eval_scores_cs2_lj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21664ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in lj_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5516de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LJ EER:  0.0\n"
     ]
    }
   ],
   "source": [
    "eer_lj = getEER(eval_score_path)\n",
    "print('LJ EER: ', eer_lj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8079b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff8c449e",
   "metadata": {},
   "source": [
    "# Libri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afc6090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_train_protocol.txt\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri/train/\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79ac9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "libri_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92d9ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS2_AASIST-L_ep100_bs24/eval_scores_cs2_libri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab582bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in libri_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29383bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libri EER:  0.0\n"
     ]
    }
   ],
   "source": [
    "eer_libri = getEER(eval_score_path)\n",
    "print('Libri EER: ', eer_libri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06298918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cc6c288",
   "metadata": {},
   "source": [
    "# CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c0e84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_train_protocol.txt\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU/train/\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa786379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "cmu_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52d17eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS2_AASIST-L_ep100_bs24/eval_scores_cs2_cmu.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1068f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in cmu_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a5e39d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU EER:  0.0\n"
     ]
    }
   ],
   "source": [
    "eer_cmu = getEER(eval_score_path)\n",
    "print('CMU EER: ', eer_cmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b62052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6336a36a",
   "metadata": {},
   "source": [
    "# ASVspoof 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98756edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_trial_path = Path('/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt')\n",
    "eval_database_path = Path('/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_eval/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea08a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSpoof_list1(dir_meta, is_train=False, is_eval=False):\n",
    "\n",
    "    d_meta = {}\n",
    "    file_list = []\n",
    "    with open(dir_meta, \"r\") as f:\n",
    "        l_meta = f.readlines()\n",
    "\n",
    "    if is_train:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list\n",
    "\n",
    "    elif is_eval:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, _ = line.strip().split(\" \")\n",
    "            #key = line.strip()\n",
    "            file_list.append(key)\n",
    "        return file_list\n",
    "    else:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "181de04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_eval = genSpoof_list1(dir_meta=eval_trial_path,\n",
    "                          is_train=False,\n",
    "                          is_eval=True)\n",
    "eval_set = Dataset_ASVspoof2019_devNeval(list_IDs=file_eval,\n",
    "                                         base_dir=eval_database_path)\n",
    "eval_loader = DataLoader(eval_set,\n",
    "                         batch_size=config[\"batch_size\"],\n",
    "                         shuffle=False,\n",
    "                         drop_last=False,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8fe931e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0009, 0.0008, 0.0007,  ..., 0.1776, 0.1562, 0.1233]),\n",
       " 'LA_E_2834763')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2188eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS2_AASIST-L_ep100_bs24/eval_scores_cs2_asv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ee5c6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/eval_scores_cs2_asv\n"
     ]
    }
   ],
   "source": [
    "trial_path = eval_trial_path\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in eval_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "print(\"Scores saved to {}\".format(eval_score_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4b594df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_lines) == len(fname_list) == len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d81b2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEER1(score_path):\n",
    "    cm_data = np.genfromtxt(score_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 2]\n",
    "    cm_scores = cm_data[:, 3].astype(float)\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "    return eer_cm * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c01fa5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASV EER:  10.343822016676695\n"
     ]
    }
   ],
   "source": [
    "eer_asv = getEER1(eval_score_path)\n",
    "print('ASV EER: ', eer_asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5cf6840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03759471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CS2_AASIST-L_ep100_bs24/eval_scores_cs2_asv\n"
     ]
    }
   ],
   "source": [
    "produce_evaluation_file(eval_loader, model, device, eval_score_path,\n",
    "                            eval_trial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50db4f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASV EER:  10.343822016676695\n"
     ]
    }
   ],
   "source": [
    "eer_asv = getEER1(eval_score_path)\n",
    "print('ASV EER: ', eer_asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0123a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d3e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
