{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a26402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "from shutil import copy\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "from data_utils import (Dataset_ASVspoof2019_train,\n",
    "                        Dataset_ASVspoof2019_devNeval, genSpoof_list_prevDbs,\n",
    "                        Dataset_train_prevDbs, Dataset_PrevDbs)\n",
    "from evaluation import calculate_tDCF_EER\n",
    "from utils import create_optimizer, seed_worker, set_seed, str_to_bool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f6d01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"database_path\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU/\",\n",
    "#     \"asv_score_path\": \"ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.eval.gi.trl.scores.txt\",\n",
    "    \"model_path\": \"./models/weights/AASIST-L.pth\",\n",
    "    \"batch_size\": 24,\n",
    "    \"num_epochs\": 100,\n",
    "    \"loss\": \"CCE\",\n",
    "    \"track\": \"LA\",\n",
    "    \"eval_all_best\": \"True\",\n",
    "    \"eval_output\": \"eval_scores_cmu_cmu.txt\",\n",
    "    \"cudnn_deterministic_toggle\": \"True\",\n",
    "    \"cudnn_benchmark_toggle\": \"False\",\n",
    "    \"model_config\": {\n",
    "        \"architecture\": \"AASIST\",\n",
    "        \"nb_samp\": 64600,\n",
    "        \"first_conv\": 128,\n",
    "        \"filts\": [70, [1, 32], [32, 32], [32, 24], [24, 24]],\n",
    "        \"gat_dims\": [24, 32],\n",
    "        \"pool_ratios\": [0.4, 0.5, 0.7, 0.5],\n",
    "        \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n",
    "    },\n",
    "    \"optim_config\": {\n",
    "        \"optimizer\": \"adam\", \n",
    "        \"amsgrad\": \"False\",\n",
    "        \"base_lr\": 0.0001,\n",
    "        \"lr_min\": 0.000005,\n",
    "        \"betas\": [0.9, 0.999],\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"scheduler\": \"cosine\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853a92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = config[\"model_config\"]\n",
    "optim_config = config[\"optim_config\"]\n",
    "optim_config[\"epochs\"] = config[\"num_epochs\"]\n",
    "# track = config[\"track\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13338120",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"eval_all_best\" not in config:\n",
    "    config[\"eval_all_best\"] = \"True\"\n",
    "if \"freq_aug\" not in config:\n",
    "    config[\"freq_aug\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10844a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1234, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f066cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random \n",
    " \n",
    "# fin = open(\"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_train_protocol.txt\", 'rb') \n",
    "# f90out = open(\"./protocols/cmu_split_train.txt\", 'wb') \n",
    "# f10out = open(\"./protocols/cmu_split_dev.txt\", 'wb') \n",
    "# for line in fin: \n",
    "#     r = random.random() \n",
    "#     if r < 0.90: \n",
    "#         f90out.write(line) \n",
    "#     else: \n",
    "#         f10out.write(line) \n",
    "# fin.close() \n",
    "# f90out.close() \n",
    "# f10out.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6315804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d7901e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"database_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716fd095",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('./exp_result')\n",
    "# prefix_2019 = \"cmu.{}\".format(track)\n",
    "database_path = Path(config[\"database_path\"])\n",
    "dev_trial_path = Path('./protocols/cmu_split_dev.txt')\n",
    "# (database_path /\n",
    "#                     \"ASVspoof2019_{}_cm_protocols/{}.cm.dev.trl.txt\".format(\n",
    "#                         track, prefix_2019))\n",
    "eval_trial_path = Path('/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_test_protocol.txt')\n",
    "# (\n",
    "#     database_path /\n",
    "#     \"ASVspoof2019_{}_cm_protocols/{}.cm.eval.trl.txt\".format(\n",
    "#         track, prefix_2019))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2459968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model related paths\n",
    "model_tag = \"{}_{}_ep{}_bs{}\".format(\n",
    "    'CMU',\n",
    "    'AASIST-L',\n",
    "    config[\"num_epochs\"], config[\"batch_size\"])\n",
    "# if args.comment:\n",
    "#     model_tag = model_tag + \"_{}\".format(args.comment)\n",
    "model_tag = output_dir / model_tag\n",
    "model_save_path = model_tag / \"weights\"\n",
    "eval_score_path = model_tag / config[\"eval_output\"]\n",
    "writer = SummaryWriter(model_tag)\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "# copy(args.config, model_tag / \"config.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91cb06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_config: Dict, device: torch.device):\n",
    "    \"\"\"Define DNN model architecture\"\"\"\n",
    "    module = import_module(\"models.{}\".format(model_config[\"architecture\"]))\n",
    "    _model = getattr(module, \"Model\")\n",
    "    model = _model(model_config).to(device)\n",
    "    nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "    print(\"no. model params:{}\".format(nb_params))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "916f6d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "no. model params:85306\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: {}\".format(device))\n",
    "if device == \"cpu\":\n",
    "    raise ValueError(\"GPU not detected!\")\n",
    "\n",
    "# define model architecture\n",
    "model = get_model(model_config, device)\n",
    "\n",
    "# # define dataloaders\n",
    "# trn_loader, dev_loader, eval_loader = get_loader(\n",
    "#     database_path, 1234, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc34d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "807c30b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. training files: 987\n",
      "no. validation files: 123\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Make PyTorch DataLoaders for train / developement / evaluation\"\"\"\n",
    "# track = config[\"track\"]\n",
    "# prefix_2019 = \"ASVspoof2019.{}\".format(track)\n",
    "\n",
    "trn_database_path = database_path / 'train'#\"ASVspoof2019_{}_train/\".format(track)\n",
    "dev_database_path = database_path / 'train'#\"ASVspoof2019_{}_dev/\".format(track)\n",
    "eval_database_path = database_path / 'test'#\"ASVspoof2019_{}_eval/\".format(track)\n",
    "\n",
    "trn_list_path = Path('./protocols/cmu_split_train.txt')\n",
    "# (database_path /\n",
    "#                  \"ASVspoof2019_{}_cm_protocols/{}.cm.train.trn.txt\".format(\n",
    "#                      track, prefix_2019))\n",
    "dev_trial_path = './protocols/cmu_split_dev.txt'\n",
    "# (database_path /\n",
    "#                   \"ASVspoof2019_{}_cm_protocols/{}.cm.dev.trl.txt\".format(\n",
    "#                       track, prefix_2019))\n",
    "eval_trial_path = '/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_test_protocol.txt'\n",
    "# (\n",
    "#     database_path /\n",
    "#     \"ASVspoof2019_{}_cm_protocols/{}.cm.eval.trl.txt\".format(\n",
    "#         track, prefix_2019))\n",
    "\n",
    "d_label_trn, file_train = genSpoof_list_prevDbs(dir_meta=trn_list_path,\n",
    "                                        is_train=True,\n",
    "                                        is_eval=False)\n",
    "print(\"no. training files:\", len(file_train))\n",
    "\n",
    "train_set = Dataset_train_prevDbs(list_IDs=file_train,\n",
    "                                       labels=d_label_trn,\n",
    "                                       base_dir=trn_database_path)\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(1234)\n",
    "trn_loader = DataLoader(train_set,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        pin_memory=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=gen)\n",
    "\n",
    "_, file_dev = genSpoof_list_prevDbs(dir_meta=dev_trial_path,\n",
    "                            is_train=False,\n",
    "                            is_eval=False)\n",
    "print(\"no. validation files:\", len(file_dev))\n",
    "\n",
    "dev_set = Dataset_PrevDbs(list_IDs=file_dev,\n",
    "                                        base_dir=dev_database_path)\n",
    "dev_loader = DataLoader(dev_set,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "file_eval = genSpoof_list_prevDbs(dir_meta=eval_trial_path,\n",
    "                          is_train=False,\n",
    "                          is_eval=True)\n",
    "eval_set = Dataset_PrevDbs(list_IDs=file_eval,\n",
    "                                         base_dir=eval_database_path)\n",
    "eval_loader = DataLoader(eval_set,\n",
    "                         batch_size=config[\"batch_size\"],\n",
    "                         shuffle=False,\n",
    "                         drop_last=False,\n",
    "                         pin_memory=True)\n",
    "\n",
    "# return trn_loader, dev_loader, eval_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb8a10e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get optimizer and scheduler\n",
    "optim_config[\"steps_per_epoch\"] = len(trn_loader)\n",
    "optimizer, scheduler = create_optimizer(model.parameters(), optim_config)\n",
    "optimizer_swa = SWA(optimizer)\n",
    "\n",
    "best_dev_eer = 1.\n",
    "best_eval_eer = 100.\n",
    "best_dev_tdcf = 0.05\n",
    "best_eval_tdcf = 1.\n",
    "n_swa_update = 0  # number of snapshots of model to use in SWA\n",
    "f_log = open(model_tag / \"metric_log.txt\", \"a\")\n",
    "f_log.write(\"=\" * 5 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85d568f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('exp_result/CMU_AASIST-L_ep100_bs24')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "989a4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory for metric logging\n",
    "metric_path = model_tag / \"metrics\"\n",
    "os.makedirs(metric_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7dad909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            utt_id, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} \\n\".format(utt_id, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    trn_loader: DataLoader,\n",
    "    model,\n",
    "    optim: Union[torch.optim.SGD, torch.optim.Adam],\n",
    "    device: torch.device,\n",
    "    scheduler: torch.optim.lr_scheduler,\n",
    "    config: argparse.Namespace):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    running_loss = 0\n",
    "    num_total = 0.0\n",
    "    ii = 0\n",
    "    model.train()\n",
    "\n",
    "    # set objective (Loss) functions\n",
    "    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    for batch_x, batch_y in trn_loader:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        ii += 1\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        _, batch_out = model(batch_x, Freq_aug=str_to_bool(config[\"freq_aug\"]))\n",
    "        batch_loss = criterion(batch_out, batch_y)\n",
    "        running_loss += batch_loss.item() * batch_size\n",
    "        optim.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if config[\"optim_config\"][\"scheduler\"] in [\"cosine\", \"keras_decay\"]:\n",
    "            scheduler.step()\n",
    "        elif scheduler is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"scheduler error, got:{}\".format(scheduler))\n",
    "\n",
    "    running_loss /= num_total\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9179f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluation import compute_eer\n",
    "def getEER(score_path):\n",
    "    cm_data = np.genfromtxt(score_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 1]\n",
    "    cm_scores = cm_data[:, 2].astype(float)\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "    return eer_cm * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff82fc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training epoch000\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.08438, dev_eer: 1.629\n",
      "Start training epoch001\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.08104, dev_eer: 0.000\n",
      "best model find at epoch 1\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch001, \n",
      "Saving epoch 1 for swa\n",
      "Start training epoch002\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06457, dev_eer: 0.000\n",
      "best model find at epoch 2\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch002, \n",
      "Saving epoch 2 for swa\n",
      "Start training epoch003\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06005, dev_eer: 0.000\n",
      "best model find at epoch 3\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch003, \n",
      "Saving epoch 3 for swa\n",
      "Start training epoch004\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06140, dev_eer: 1.629\n",
      "Start training epoch005\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04745, dev_eer: 0.000\n",
      "best model find at epoch 5\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch005, \n",
      "Saving epoch 5 for swa\n",
      "Start training epoch006\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04668, dev_eer: 0.000\n",
      "best model find at epoch 6\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch006, \n",
      "Saving epoch 6 for swa\n",
      "Start training epoch007\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03593, dev_eer: 0.000\n",
      "best model find at epoch 7\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch007, \n",
      "Saving epoch 7 for swa\n",
      "Start training epoch008\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.05355, dev_eer: 0.000\n",
      "best model find at epoch 8\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch008, \n",
      "Saving epoch 8 for swa\n",
      "Start training epoch009\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03963, dev_eer: 0.000\n",
      "best model find at epoch 9\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch009, \n",
      "Saving epoch 9 for swa\n",
      "Start training epoch010\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03546, dev_eer: 0.000\n",
      "best model find at epoch 10\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch010, \n",
      "Saving epoch 10 for swa\n",
      "Start training epoch011\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03890, dev_eer: 0.000\n",
      "best model find at epoch 11\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch011, \n",
      "Saving epoch 11 for swa\n",
      "Start training epoch012\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02441, dev_eer: 0.000\n",
      "best model find at epoch 12\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch012, \n",
      "Saving epoch 12 for swa\n",
      "Start training epoch013\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03529, dev_eer: 0.000\n",
      "best model find at epoch 13\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch013, \n",
      "Saving epoch 13 for swa\n",
      "Start training epoch014\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02772, dev_eer: 0.000\n",
      "best model find at epoch 14\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch014, \n",
      "Saving epoch 14 for swa\n",
      "Start training epoch015\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02586, dev_eer: 0.000\n",
      "best model find at epoch 15\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch015, \n",
      "Saving epoch 15 for swa\n",
      "Start training epoch016\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03371, dev_eer: 0.000\n",
      "best model find at epoch 16\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch016, \n",
      "Saving epoch 16 for swa\n",
      "Start training epoch017\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02633, dev_eer: 0.000\n",
      "best model find at epoch 17\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch017, \n",
      "Saving epoch 17 for swa\n",
      "Start training epoch018\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02412, dev_eer: 0.000\n",
      "best model find at epoch 18\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch018, \n",
      "Saving epoch 18 for swa\n",
      "Start training epoch019\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02444, dev_eer: 0.000\n",
      "best model find at epoch 19\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch019, \n",
      "Saving epoch 19 for swa\n",
      "Start training epoch020\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03750, dev_eer: 0.000\n",
      "best model find at epoch 20\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch020, \n",
      "Saving epoch 20 for swa\n",
      "Start training epoch021\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01924, dev_eer: 0.000\n",
      "best model find at epoch 21\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch021, \n",
      "Saving epoch 21 for swa\n",
      "Start training epoch022\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03338, dev_eer: 0.000\n",
      "best model find at epoch 22\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch022, \n",
      "Saving epoch 22 for swa\n",
      "Start training epoch023\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03226, dev_eer: 0.000\n",
      "best model find at epoch 23\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch023, \n",
      "Saving epoch 23 for swa\n",
      "Start training epoch024\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01792, dev_eer: 0.000\n",
      "best model find at epoch 24\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch024, \n",
      "Saving epoch 24 for swa\n",
      "Start training epoch025\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01705, dev_eer: 0.000\n",
      "best model find at epoch 25\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch025, \n",
      "Saving epoch 25 for swa\n",
      "Start training epoch026\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01475, dev_eer: 0.000\n",
      "best model find at epoch 26\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch026, \n",
      "Saving epoch 26 for swa\n",
      "Start training epoch027\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02371, dev_eer: 0.000\n",
      "best model find at epoch 27\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch027, \n",
      "Saving epoch 27 for swa\n",
      "Start training epoch028\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02000, dev_eer: 0.000\n",
      "best model find at epoch 28\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch028, \n",
      "Saving epoch 28 for swa\n",
      "Start training epoch029\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01458, dev_eer: 0.000\n",
      "best model find at epoch 29\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch029, \n",
      "Saving epoch 29 for swa\n",
      "Start training epoch030\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01881, dev_eer: 0.000\n",
      "best model find at epoch 30\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch030, \n",
      "Saving epoch 30 for swa\n",
      "Start training epoch031\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01507, dev_eer: 0.000\n",
      "best model find at epoch 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch031, \n",
      "Saving epoch 31 for swa\n",
      "Start training epoch032\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01475, dev_eer: 0.000\n",
      "best model find at epoch 32\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch032, \n",
      "Saving epoch 32 for swa\n",
      "Start training epoch033\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01071, dev_eer: 0.000\n",
      "best model find at epoch 33\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch033, \n",
      "Saving epoch 33 for swa\n",
      "Start training epoch034\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00903, dev_eer: 0.000\n",
      "best model find at epoch 34\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch034, \n",
      "Saving epoch 34 for swa\n",
      "Start training epoch035\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01856, dev_eer: 0.000\n",
      "best model find at epoch 35\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch035, \n",
      "Saving epoch 35 for swa\n",
      "Start training epoch036\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01371, dev_eer: 0.000\n",
      "best model find at epoch 36\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch036, \n",
      "Saving epoch 36 for swa\n",
      "Start training epoch037\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01723, dev_eer: 0.000\n",
      "best model find at epoch 37\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch037, \n",
      "Saving epoch 37 for swa\n",
      "Start training epoch038\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01117, dev_eer: 0.000\n",
      "best model find at epoch 38\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch038, \n",
      "Saving epoch 38 for swa\n",
      "Start training epoch039\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01070, dev_eer: 0.000\n",
      "best model find at epoch 39\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch039, \n",
      "Saving epoch 39 for swa\n",
      "Start training epoch040\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00853, dev_eer: 0.000\n",
      "best model find at epoch 40\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch040, \n",
      "Saving epoch 40 for swa\n",
      "Start training epoch041\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01408, dev_eer: 0.000\n",
      "best model find at epoch 41\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch041, \n",
      "Saving epoch 41 for swa\n",
      "Start training epoch042\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01486, dev_eer: 0.000\n",
      "best model find at epoch 42\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch042, \n",
      "Saving epoch 42 for swa\n",
      "Start training epoch043\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01634, dev_eer: 0.000\n",
      "best model find at epoch 43\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch043, \n",
      "Saving epoch 43 for swa\n",
      "Start training epoch044\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00537, dev_eer: 0.000\n",
      "best model find at epoch 44\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch044, \n",
      "Saving epoch 44 for swa\n",
      "Start training epoch045\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01066, dev_eer: 0.000\n",
      "best model find at epoch 45\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch045, \n",
      "Saving epoch 45 for swa\n",
      "Start training epoch046\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00714, dev_eer: 0.000\n",
      "best model find at epoch 46\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch046, \n",
      "Saving epoch 46 for swa\n",
      "Start training epoch047\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00770, dev_eer: 0.000\n",
      "best model find at epoch 47\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch047, \n",
      "Saving epoch 47 for swa\n",
      "Start training epoch048\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01049, dev_eer: 0.000\n",
      "best model find at epoch 48\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch048, \n",
      "Saving epoch 48 for swa\n",
      "Start training epoch049\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00770, dev_eer: 0.000\n",
      "best model find at epoch 49\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch049, \n",
      "Saving epoch 49 for swa\n",
      "Start training epoch050\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00928, dev_eer: 0.000\n",
      "best model find at epoch 50\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch050, \n",
      "Saving epoch 50 for swa\n",
      "Start training epoch051\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00909, dev_eer: 0.000\n",
      "best model find at epoch 51\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch051, \n",
      "Saving epoch 51 for swa\n",
      "Start training epoch052\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01071, dev_eer: 0.000\n",
      "best model find at epoch 52\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "epoch052, \n",
      "Saving epoch 52 for swa\n",
      "Start training epoch053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training epoch\u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[0;32m----> 4\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     produce_evaluation_file(dev_loader, model, device,\n\u001b[1;32m      7\u001b[0m                             metric_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_score.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, dev_trial_path)\n\u001b[1;32m      8\u001b[0m     dev_eer \u001b[38;5;241m=\u001b[39m getEER(metric_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_score.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 47\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(trn_loader, model, optim, device, scheduler, config)\u001b[0m\n\u001b[1;32m     45\u001b[0m weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.9\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     46\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(weight\u001b[38;5;241m=\u001b[39mweight)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m trn_loader:\n\u001b[1;32m     48\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     49\u001b[0m     num_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[0;32m/DATA/Lalaram_DS2ST_Trans/miniconda3/envs/aasist_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/DATA/Lalaram_DS2ST_Trans/miniconda3/envs/aasist_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/DATA/Lalaram_DS2ST_Trans/miniconda3/envs/aasist_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/DATA/Lalaram_DS2ST_Trans/miniconda3/envs/aasist_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/DATA/Rishith/aasist/data_utils.py:123\u001b[0m, in \u001b[0;36mDataset_train_prevDbs.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m    122\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlist_IDs[index]\n\u001b[0;32m--> 123\u001b[0m     X, _ \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     X_pad \u001b[38;5;241m=\u001b[39m pad_random(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcut)\n\u001b[1;32m    125\u001b[0m     x_inp \u001b[38;5;241m=\u001b[39m Tensor(X_pad)\n",
      "File \u001b[0;32m/DATA/Lalaram_DS2ST_Trans/miniconda3/envs/aasist_env/lib/python3.10/site-packages/soundfile.py:288\u001b[0m, in \u001b[0;36mread\u001b[0;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SoundFile(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, samplerate, channels,\n\u001b[1;32m    286\u001b[0m                subtype, endian, \u001b[38;5;28mformat\u001b[39m, closefd) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    287\u001b[0m     frames \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39m_prepare_read(start, stop, frames)\n\u001b[0;32m--> 288\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, f\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[0;32m/DATA/Lalaram_DS2ST_Trans/miniconda3/envs/aasist_env/lib/python3.10/site-packages/soundfile.py:895\u001b[0m, in \u001b[0;36mSoundFile.read\u001b[0;34m(self, frames, dtype, always_2d, fill_value, out)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frames \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m frames \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(out):\n\u001b[1;32m    894\u001b[0m         frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[0;32m--> 895\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_array_io\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m>\u001b[39m frames:\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/DATA/Lalaram_DS2ST_Trans/miniconda3/envs/aasist_env/lib/python3.10/site-packages/soundfile.py:1344\u001b[0m, in \u001b[0;36mSoundFile._array_io\u001b[0;34m(self, action, array, frames)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mitemsize \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39msizeof(ctype)\n\u001b[1;32m   1343\u001b[0m cdata \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mcast(ctype \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m, array\u001b[38;5;241m.\u001b[39m__array_interface__[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 1344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cdata_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/DATA/Lalaram_DS2ST_Trans/miniconda3/envs/aasist_env/lib/python3.10/site-packages/soundfile.py:1353\u001b[0m, in \u001b[0;36mSoundFile._cdata_io\u001b[0;34m(self, action, data, ctype, frames)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m   1352\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_snd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m action \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m ctype)\n\u001b[0;32m-> 1353\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m _error_check(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_errorcode)\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    print(\"Start training epoch{:03d}\".format(epoch))\n",
    "    running_loss = train_epoch(trn_loader, model, optimizer, device,\n",
    "                               scheduler, config)\n",
    "    produce_evaluation_file(dev_loader, model, device,\n",
    "                            metric_path/\"dev_score.txt\", dev_trial_path)\n",
    "    dev_eer = getEER(metric_path/\"dev_score.txt\")\n",
    "#     , dev_tdcf = calculate_tDCF_EER(\n",
    "#         cm_scores_file=metric_path/\"dev_score.txt\",\n",
    "#         asv_score_file=database_path/config[\"asv_score_path\"],\n",
    "#         output_file=metric_path/\"dev_t-DCF_EER_{}epo.txt\".format(epoch),\n",
    "#         printout=False)\n",
    "    print(\"DONE.\\nLoss:{:.5f}, dev_eer: {:.3f}\".format(\n",
    "        running_loss, dev_eer))\n",
    "    writer.add_scalar(\"loss\", running_loss, epoch)\n",
    "    writer.add_scalar(\"dev_eer\", dev_eer, epoch)\n",
    "#     writer.add_scalar(\"dev_tdcf\", dev_tdcf, epoch)\n",
    "\n",
    "#     best_dev_tdcf = min(dev_tdcf, best_dev_tdcf)\n",
    "    if best_dev_eer >= dev_eer:\n",
    "        print(\"best model find at epoch\", epoch)\n",
    "        best_dev_eer = dev_eer\n",
    "        torch.save(model.state_dict(),\n",
    "                   model_save_path / \"epoch_{}_{:03.3f}.pth\".format(epoch, dev_eer))\n",
    "\n",
    "        # do evaluation whenever best model is renewed\n",
    "        if str_to_bool(config[\"eval_all_best\"]):\n",
    "            produce_evaluation_file(eval_loader, model, device,\n",
    "                                    eval_score_path, eval_trial_path)\n",
    "            dev_eer = getEER(metric_path/\"dev_score.txt\")\n",
    "            eval_eer = getEER(eval_score_path)\n",
    "#             , eval_tdcf = calculate_tDCF_EER(\n",
    "#                 cm_scores_file=eval_score_path,\n",
    "#                 asv_score_file=database_path / config[\"asv_score_path\"],\n",
    "#                 output_file=metric_path /\n",
    "#                 \"t-DCF_EER_{:03d}epo.txt\".format(epoch))\n",
    "\n",
    "            log_text = \"epoch{:03d}, \".format(epoch)\n",
    "            if eval_eer < best_eval_eer:\n",
    "                log_text += \"best eer, {:.4f}%\".format(eval_eer)\n",
    "                best_eval_eer = eval_eer\n",
    "                torch.save(model.state_dict(),\n",
    "                           model_save_path / \"best.pth\")\n",
    "#             if eval_tdcf < best_eval_tdcf:\n",
    "#                 log_text += \"best tdcf, {:.4f}\".format(eval_tdcf)\n",
    "#                 best_eval_tdcf = eval_tdcf\n",
    "#                 torch.save(model.state_dict(),\n",
    "#                            model_save_path / \"best.pth\")\n",
    "            if len(log_text) > 0:\n",
    "                print(log_text)\n",
    "                f_log.write(log_text + \"\\n\")\n",
    "\n",
    "        print(\"Saving epoch {} for swa\".format(epoch))\n",
    "        optimizer_swa.update_swa()\n",
    "        n_swa_update += 1\n",
    "    writer.add_scalar(\"best_dev_eer\", best_dev_eer, epoch)\n",
    "    writer.add_scalar(\"best_dev_tdcf\", best_dev_tdcf, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e48b14f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start final evaluation\n",
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_cmu.txt\n",
      "Exp FIN. EER: 0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Start final evaluation\")\n",
    "epoch += 1\n",
    "if n_swa_update > 0:\n",
    "    optimizer_swa.swap_swa_sgd()\n",
    "    optimizer_swa.bn_update(trn_loader, model, device=device)\n",
    "produce_evaluation_file(eval_loader, model, device, eval_score_path,\n",
    "                        eval_trial_path)\n",
    "eval_eer = getEER(eval_score_path)\n",
    "# , eval_tdcf = calculate_tDCF_EER(cm_scores_file=eval_score_path,\n",
    "#                                          asv_score_file=database_path /\n",
    "#                                          config[\"asv_score_path\"],\n",
    "#                                          output_file=model_tag / \"t-DCF_EER.txt\")\n",
    "f_log = open(model_tag / \"metric_log.txt\", \"a\")\n",
    "f_log.write(\"=\" * 5 + \"\\n\")\n",
    "f_log.write(\"EER: {:.3f}\".format(eval_eer))\n",
    "f_log.close()\n",
    "\n",
    "torch.save(model.state_dict(),\n",
    "           model_save_path / \"swa.pth\")\n",
    "\n",
    "if eval_eer <= best_eval_eer:\n",
    "    best_eval_eer = eval_eer\n",
    "# if eval_tdcf <= best_eval_tdcf:\n",
    "#     best_eval_tdcf = eval_tdcf\n",
    "    torch.save(model.state_dict(),\n",
    "               model_save_path / \"best.pth\")\n",
    "print(\"Exp FIN. EER: {:.3f}\".format(\n",
    "    best_eval_eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eab19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34632bd6",
   "metadata": {},
   "source": [
    "# LJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c027481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/lj_train_protocol.txt\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/lj_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/LJ/train/\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/LJ/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53b61b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "lj_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ffb2f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv_time): CONV()\n",
       "  (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.5, inplace=True)\n",
       "  (drop_way): Dropout(p=0.2, inplace=True)\n",
       "  (selu): SELU(inplace=True)\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (conv1): Conv2d(1, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(32, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (GAT_layer_S): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (GAT_layer_T): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST11): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_type2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (att_proj): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST12): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST21): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_type2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (att_proj): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST22): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (pool_S): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=24, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_T): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=24, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (out_layer): Linear(in_features=160, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bef6d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_lj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99246a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in lj_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ada5d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LJ EER:  36.734693877551024\n"
     ]
    }
   ],
   "source": [
    "eer_lj = getEER(eval_score_path)\n",
    "print('LJ EER: ', eer_lj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac221f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b326024f",
   "metadata": {},
   "source": [
    "# Libri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35681607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_train_protocol.txt\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri/train/\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81a5312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "libri_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "032c5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_libri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d87f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in libri_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd6f4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libri EER:  28.57142857142857\n"
     ]
    }
   ],
   "source": [
    "eer_libri = getEER(eval_score_path)\n",
    "print('Libri EER: ', eer_libri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e4fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26e9465e",
   "metadata": {},
   "source": [
    "# ASVspoof 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27fb40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_trial_path = Path('/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt')\n",
    "eval_database_path = Path('/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_eval/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9781c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSpoof_list1(dir_meta, is_train=False, is_eval=False):\n",
    "\n",
    "    d_meta = {}\n",
    "    file_list = []\n",
    "    with open(dir_meta, \"r\") as f:\n",
    "        l_meta = f.readlines()\n",
    "\n",
    "    if is_train:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list\n",
    "\n",
    "    elif is_eval:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, _ = line.strip().split(\" \")\n",
    "            #key = line.strip()\n",
    "            file_list.append(key)\n",
    "        return file_list\n",
    "    else:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf35cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_eval = genSpoof_list1(dir_meta=eval_trial_path,\n",
    "                          is_train=False,\n",
    "                          is_eval=True)\n",
    "eval_set = Dataset_ASVspoof2019_devNeval(list_IDs=file_eval,\n",
    "                                         base_dir=eval_database_path)\n",
    "eval_loader = DataLoader(eval_set,\n",
    "                         batch_size=config[\"batch_size\"],\n",
    "                         shuffle=False,\n",
    "                         drop_last=False,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7621fe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0009, 0.0008, 0.0007,  ..., 0.1776, 0.1562, 0.1233]),\n",
       " 'LA_E_2834763')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e8325b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_asv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "919b2b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_trial_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c7f5d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_asv\n"
     ]
    }
   ],
   "source": [
    "trial_path = eval_trial_path\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in eval_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "print(\"Scores saved to {}\".format(eval_score_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48a8d5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LA_E_2834763', 'A11', 'spoof', '-0.0017449557781219482'],\n",
       "      dtype='<U22')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_data = np.genfromtxt(eval_score_path, dtype=str)\n",
    "cm_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8f54f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEER1(score_path):\n",
    "    cm_data = np.genfromtxt(score_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 2]\n",
    "    cm_scores = cm_data[:, 3].astype(float)\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "    return eer_cm * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53670a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASV EER:  18.38219147297221\n"
     ]
    }
   ],
   "source": [
    "eer_asv = getEER1(eval_score_path)\n",
    "print('ASV EER: ', eer_asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4f4f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e56bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CMU_AASIST-L_ep100_bs24/eval_scores_cmu_asv\n"
     ]
    }
   ],
   "source": [
    "produce_evaluation_file(eval_loader, model, device, eval_score_path,\n",
    "                            SET_CM_PROTOCOL['eval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e446a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASV EER:  18.38219147297221\n"
     ]
    }
   ],
   "source": [
    "eer_asv = getEER1(eval_score_path)\n",
    "print('ASV EER: ', eer_asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432df429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
