{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78665c19",
   "metadata": {},
   "source": [
    "# Combined Set 3:\n",
    "Train Set: ASVspoof train (all samples) + prev datasets (90% of train set)\n",
    "\n",
    "Dev set: ASVspoof dev (ass samples) + prev datasets (10% of train set)\n",
    "\n",
    "Test set: ASVspoof eval (all samples) + prev datasets (all samples of test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b2a875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a7b1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffc5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "from shutil import copy\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "from data_utils import (Dataset_ASVspoof2019_train,\n",
    "                        Dataset_ASVspoof2019_devNeval, genSpoof_list_prevDbs, genSpoof_list,\n",
    "                        Dataset_train_prevDbs, Dataset_PrevDbs, Dataset_cs2, Dataset_train_cs2)\n",
    "from evaluation import calculate_tDCF_EER\n",
    "from utils import create_optimizer, seed_worker, set_seed, str_to_bool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3929a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2ffeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"database_path\": '/data/nfsshare/rishith/datasets/smaller_dbs/restructured/combinedSet3/',\n",
    "#     \"asv_score_path\": \"ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.eval.gi.trl.scores.txt\",\n",
    "    \"model_path\": \"./models/weights/AASIST-L.pth\",\n",
    "    \"batch_size\": 24,\n",
    "    \"num_epochs\": 100,\n",
    "    \"loss\": \"CCE\",\n",
    "    \"track\": \"LA\",\n",
    "    \"eval_all_best\": \"True\",\n",
    "    \"eval_output\": \"eval_scores_cs3_cs3.txt\",\n",
    "    \"cudnn_deterministic_toggle\": \"True\",\n",
    "    \"cudnn_benchmark_toggle\": \"False\",\n",
    "    \"model_config\": {\n",
    "        \"architecture\": \"AASIST\",\n",
    "        \"nb_samp\": 64600,\n",
    "        \"first_conv\": 128,\n",
    "        \"filts\": [70, [1, 32], [32, 32], [32, 24], [24, 24]],\n",
    "        \"gat_dims\": [24, 32],\n",
    "        \"pool_ratios\": [0.4, 0.5, 0.7, 0.5],\n",
    "        \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n",
    "    },\n",
    "    \"optim_config\": {\n",
    "        \"optimizer\": \"adam\", \n",
    "        \"amsgrad\": \"False\",\n",
    "        \"base_lr\": 0.0001,\n",
    "        \"lr_min\": 0.000005,\n",
    "        \"betas\": [0.9, 0.999],\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"scheduler\": \"cosine\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9257394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = config[\"model_config\"]\n",
    "optim_config = config[\"optim_config\"]\n",
    "optim_config[\"epochs\"] = config[\"num_epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a203b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"eval_all_best\" not in config:\n",
    "    config[\"eval_all_best\"] = \"True\"\n",
    "if \"freq_aug\" not in config:\n",
    "    config[\"freq_aug\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72dd136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1234, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1429ee0",
   "metadata": {},
   "source": [
    "# Creating combined set 3\n",
    "Combining prev databases with entire ASVspoof data to make combined set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0e5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random \n",
    " \n",
    "# cs1 = open(\"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/combined_train_protocol.txt\", 'r')\n",
    "# asv_train_protocol = open(\"/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\", 'r')\n",
    "# asv_dev_protocol = open(\"/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\", 'r')\n",
    "# newTrain = open('./protocols/combinedSet3_train.txt', 'w')\n",
    "# newDev = open('./protocols/combinedSet3_dev.txt', 'w')\n",
    "\n",
    "# # print(len(cs1.readlines()))\n",
    "# # print(len(reduced_trainset8.readlines()))\n",
    "# # print(len(reduced_devSet.readlines()))\n",
    "\n",
    "# for line in asv_train_protocol:\n",
    "#     _, name, _, _, label = line.split(\" \")\n",
    "#     newTrain.write('- ' + name+'.flac' + ' - - ' + label)\n",
    "# for line in asv_dev_protocol:\n",
    "#     _, name, _, _, label = line.split(\" \")\n",
    "#     newDev.write('- ' + name +'.flac' + ' - - ' + label)\n",
    "# for line in cs1:\n",
    "#     name, label = line.split(\" \")\n",
    "# #     print('- ' + name + ' - - ' + label)\n",
    "#     r = random.random()\n",
    "#     if r < 0.90:\n",
    "#         newTrain.write('- ' + name + '.wav' + ' - - ' + label)\n",
    "#     else:\n",
    "#         newDev.write('- ' + name + '.wav' + ' - - ' + label)\n",
    "    \n",
    "# cs1.close()\n",
    "# asv_train_protocol.close()\n",
    "# asv_dev_protocol.close()\n",
    "# newTrain.close()\n",
    "# newDev.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bedcc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# asv_train_path = '/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_train/flac/'\n",
    "# asv_dev_path = '/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_dev/flac/'\n",
    "\n",
    "# cs1_train_path = '/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/combined/Train/'\n",
    "\n",
    "# destination_path = './combinedSet3/'\n",
    "\n",
    "# trainProtocol = open('./protocols/combinedSet3_train.txt', 'r')\n",
    "# for line in trainProtocol:\n",
    "#     _, name, _, _, _ = line.split(\" \")\n",
    "#     source_file = asv_train_path + name\n",
    "#     destination_file = destination_path + name\n",
    "#     if(os.path.isfile(source_file)):\n",
    "#         shutil.copy(source_file, destination_file)\n",
    "#     source_file = cs1_train_path + name\n",
    "#     destination_file = destination_path + name \n",
    "#     if(os.path.isfile(source_file)):\n",
    "#         shutil.copy(source_file, destination_file)\n",
    "    \n",
    "# devProtocol = open('./protocols/combinedSet3_dev.txt', 'r')\n",
    "# for line in devProtocol:\n",
    "#     _, name, _, _, _ = line.split(\" \")\n",
    "#     source_file = asv_dev_path + name \n",
    "#     destination_file = destination_path + name\n",
    "#     if(os.path.isfile(source_file)):\n",
    "#         shutil.copy(source_file, destination_file)\n",
    "#     source_file = cs1_train_path + name\n",
    "#     destination_file = destination_path + name\n",
    "#     if(os.path.isfile(source_file)):\n",
    "#         shutil.copy(source_file, destination_file)\n",
    "\n",
    "        \n",
    "# trainProtocol.close()\n",
    "# devProtocol.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aff37b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/nfsshare/rishith/datasets/smaller_dbs/restructured/combinedSet3/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"database_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8b66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('./exp_result')\n",
    "database_path = Path(config[\"database_path\"])\n",
    "dev_trial_path = Path('./protocols/combinedSet3_dev.txt')\n",
    "# eval_trial_path = Path('/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46dae22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model related paths\n",
    "model_tag = \"{}_{}_ep{}_bs{}\".format(\n",
    "    'CS3',\n",
    "    'AASIST-L',\n",
    "    config[\"num_epochs\"], config[\"batch_size\"])\n",
    "model_tag = output_dir / model_tag\n",
    "model_save_path = model_tag / \"weights\"\n",
    "eval_score_path = model_tag / config[\"eval_output\"]\n",
    "writer = SummaryWriter(model_tag)\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40eb6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_config: Dict, device: torch.device):\n",
    "    \"\"\"Define DNN model architecture\"\"\"\n",
    "    module = import_module(\"models.{}\".format(model_config[\"architecture\"]))\n",
    "    _model = getattr(module, \"Model\")\n",
    "    model = _model(model_config).to(device)\n",
    "    nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "    print(\"no. model params:{}\".format(nb_params))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "686ab894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "no. model params:85306\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: {}\".format(device))\n",
    "if device == \"cpu\":\n",
    "    raise ValueError(\"GPU not detected!\")\n",
    "\n",
    "# define model architecture\n",
    "model = get_model(model_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3109f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/nfsshare/rishith/datasets/smaller_dbs/restructured/combinedSet3')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f42be54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. training files: 27848\n",
      "no. validation files: 25146\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Make PyTorch DataLoaders for train / developement / evaluation\"\"\"\n",
    "\n",
    "trn_database_path = database_path \n",
    "dev_database_path = database_path \n",
    "\n",
    "trn_list_path = Path('./protocols/combinedSet3_train.txt')\n",
    "dev_trial_path = './protocols/combinedSet3_dev.txt'\n",
    "d_label_trn, file_train = genSpoof_list(dir_meta=trn_list_path,\n",
    "                                        is_train=True,\n",
    "                                        is_eval=False)\n",
    "print(\"no. training files:\", len(file_train))\n",
    "\n",
    "train_set = Dataset_train_cs2(list_IDs=file_train,\n",
    "                                       labels=d_label_trn,\n",
    "                                       base_dir=trn_database_path)\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(1234)\n",
    "trn_loader = DataLoader(train_set,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        pin_memory=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=gen)\n",
    "\n",
    "_, file_dev = genSpoof_list(dir_meta=dev_trial_path,\n",
    "                            is_train=False,\n",
    "                            is_eval=False)\n",
    "print(\"no. validation files:\", len(file_dev))\n",
    "\n",
    "dev_set = Dataset_cs2(list_IDs=file_dev,\n",
    "                                        base_dir=dev_database_path)\n",
    "dev_loader = DataLoader(dev_set,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c6e093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_trial_path = Path('/data/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt')\n",
    "eval_database_path = Path('/data/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_eval/')\n",
    "\n",
    "def genSpoof_list1(dir_meta, is_train=False, is_eval=False):\n",
    "\n",
    "    d_meta = {}\n",
    "    file_list = []\n",
    "    with open(dir_meta, \"r\") as f:\n",
    "        l_meta = f.readlines()\n",
    "\n",
    "    if is_train:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list\n",
    "\n",
    "    elif is_eval:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, _ = line.strip().split(\" \")\n",
    "            #key = line.strip()\n",
    "            file_list.append(key)\n",
    "        return file_list\n",
    "    else:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc50ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_eval = genSpoof_list1(dir_meta=eval_trial_path,\n",
    "                          is_train=False,\n",
    "                          is_eval=True)\n",
    "eval_set = Dataset_ASVspoof2019_devNeval(list_IDs=file_eval,\n",
    "                                         base_dir=eval_database_path)\n",
    "eval_loader = DataLoader(eval_set,\n",
    "                         batch_size=config[\"batch_size\"],\n",
    "                         shuffle=False,\n",
    "                         drop_last=False,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ad5843e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get optimizer and scheduler\n",
    "optim_config[\"steps_per_epoch\"] = len(trn_loader)\n",
    "optimizer, scheduler = create_optimizer(model.parameters(), optim_config)\n",
    "optimizer_swa = SWA(optimizer)\n",
    "\n",
    "best_dev_eer = 1.\n",
    "best_eval_eer = 100.\n",
    "best_dev_tdcf = 0.05\n",
    "best_eval_tdcf = 1.\n",
    "n_swa_update = 0  # number of snapshots of model to use in SWA\n",
    "f_log = open(model_tag / \"metric_log.txt\", \"a\")\n",
    "f_log.write(\"=\" * 5 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dda8ab93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('exp_result/CS3_AASIST-L_ep100_bs24')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45246d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory for metric logging\n",
    "metric_path = model_tag / \"metrics\"\n",
    "os.makedirs(metric_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f653c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            _, utt_id, _, _, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} \\n\".format(utt_id, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    trn_loader: DataLoader,\n",
    "    model,\n",
    "    optim: Union[torch.optim.SGD, torch.optim.Adam],\n",
    "    device: torch.device,\n",
    "    scheduler: torch.optim.lr_scheduler,\n",
    "    config: argparse.Namespace):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    running_loss = 0\n",
    "    num_total = 0.0\n",
    "    ii = 0\n",
    "    model.train()\n",
    "\n",
    "    # set objective (Loss) functions\n",
    "    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    for batch_x, batch_y in trn_loader:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        ii += 1\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        _, batch_out = model(batch_x, Freq_aug=str_to_bool(config[\"freq_aug\"]))\n",
    "        batch_loss = criterion(batch_out, batch_y)\n",
    "        running_loss += batch_loss.item() * batch_size\n",
    "        optim.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if config[\"optim_config\"][\"scheduler\"] in [\"cosine\", \"keras_decay\"]:\n",
    "            scheduler.step()\n",
    "        elif scheduler is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"scheduler error, got:{}\".format(scheduler))\n",
    "\n",
    "    running_loss /= num_total\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c70ea672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluation import compute_eer\n",
    "def getEER(score_path):\n",
    "    cm_data = np.genfromtxt(score_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 1]\n",
    "    cm_scores = cm_data[:, 2].astype(float)\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "    return eer_cm * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1be56b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0945d498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training epoch000\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.48 GiB (GPU 0; 10.76 GiB total capacity; 8.45 GiB already allocated; 383.06 MiB free; 9.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training epoch\u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[0;32m----> 4\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     produce_evaluation_file(dev_loader, model, device,\n\u001b[1;32m      7\u001b[0m                             metric_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_score.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, dev_trial_path)\n\u001b[1;32m      8\u001b[0m     dev_eer \u001b[38;5;241m=\u001b[39m getEER(metric_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_score.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 53\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(trn_loader, model, optim, device, scheduler, config)\u001b[0m\n\u001b[1;32m     51\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     52\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m batch_y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mint64)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 53\u001b[0m _, batch_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFreq_aug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstr_to_bool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfreq_aug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m criterion(batch_out, batch_y)\n\u001b[1;32m     55\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch_size\n",
      "File \u001b[0;32m/data/anaconda3/envs/aasist_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/rishith/aasist/models/AASIST.py:539\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x, Freq_aug)\u001b[0m\n\u001b[1;32m    535\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselu(x)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# get embeddings using encoder\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# (#bs, #filt, #spec, #seq)\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# spectral GAT (GAT-S)\u001b[39;00m\n\u001b[1;32m    542\u001b[0m e_S, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mabs(e), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# max along time\u001b[39;00m\n",
      "File \u001b[0;32m/data/anaconda3/envs/aasist_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/anaconda3/envs/aasist_env/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/data/anaconda3/envs/aasist_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/anaconda3/envs/aasist_env/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/data/anaconda3/envs/aasist_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/rishith/aasist/models/AASIST.py:456\u001b[0m, in \u001b[0;36mResidual_block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    453\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# print('out',out.shape)\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselu(out)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# print('out',out.shape)\u001b[39;00m\n",
      "File \u001b[0;32m/data/anaconda3/envs/aasist_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/anaconda3/envs/aasist_env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/anaconda3/envs/aasist_env/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.48 GiB (GPU 0; 10.76 GiB total capacity; 8.45 GiB already allocated; 383.06 MiB free; 9.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    print(\"Start training epoch{:03d}\".format(epoch))\n",
    "    running_loss = train_epoch(trn_loader, model, optimizer, device,\n",
    "                               scheduler, config)\n",
    "    produce_evaluation_file(dev_loader, model, device,\n",
    "                            metric_path/\"dev_score.txt\", dev_trial_path)\n",
    "    dev_eer = getEER(metric_path/\"dev_score.txt\")\n",
    "    print(\"DONE.\\nLoss:{:.5f}, dev_eer: {:.3f}\".format(\n",
    "        running_loss, dev_eer))\n",
    "    writer.add_scalar(\"loss\", running_loss, epoch)\n",
    "    writer.add_scalar(\"dev_eer\", dev_eer, epoch)\n",
    "\n",
    "    if best_dev_eer >= dev_eer:\n",
    "        print(\"best model find at epoch\", epoch)\n",
    "        best_dev_eer = dev_eer\n",
    "        torch.save(model.state_dict(),\n",
    "                   model_save_path / \"epoch_{}_{:03.3f}.pth\".format(epoch, dev_eer))\n",
    "\n",
    "        # do evaluation whenever best model is renewed\n",
    "        if str_to_bool(config[\"eval_all_best\"]):\n",
    "            produce_evaluation_file(eval_loader, model, device,\n",
    "                                    eval_score_path, eval_trial_path)\n",
    "            dev_eer = getEER(metric_path/\"dev_score.txt\")\n",
    "            eval_eer = getEER(eval_score_path)\n",
    "\n",
    "            log_text = \"epoch{:03d}, \".format(epoch)\n",
    "            if eval_eer < best_eval_eer:\n",
    "                log_text += \"best eer, {:.4f}%\".format(eval_eer)\n",
    "                best_eval_eer = eval_eer\n",
    "                torch.save(model.state_dict(),\n",
    "                           model_save_path / \"best.pth\")\n",
    "            if len(log_text) > 0:\n",
    "                print(log_text)\n",
    "                f_log.write(log_text + \"\\n\")\n",
    "\n",
    "        print(\"Saving epoch {} for swa\".format(epoch))\n",
    "        optimizer_swa.update_swa()\n",
    "        n_swa_update += 1\n",
    "    writer.add_scalar(\"best_dev_eer\", best_dev_eer, epoch)\n",
    "    writer.add_scalar(\"best_dev_tdcf\", best_dev_tdcf, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb5b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5a5b9e",
   "metadata": {},
   "source": [
    "# Testing best model after 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8925a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5775338329330904\n"
     ]
    }
   ],
   "source": [
    "eval_eer = getEER('./exp_result/CS3_AASIST-L_ep100_bs24/eval_scores_cs3_cs3.txt')\n",
    "print(eval_eer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75aa2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"model_path\"] = './exp_result/CS3_AASIST-L_ep100_bs24/weights/best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62dca0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(\n",
    "            torch.load(config[\"model_path\"], map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08ffdf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded : ./exp_result/CS3_AASIST-L_ep100_bs24/weights/best.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Model loaded : {}\".format(config[\"model_path\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77bd37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea7c5a77",
   "metadata": {},
   "source": [
    "# LJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1200fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/lj_train_protocol.txt\",\n",
    "    \"eval\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/lj_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/LJ/train/\",\n",
    "    \"eval\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/LJ/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "183cca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "lj_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e64093f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv_time): CONV()\n",
       "  (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.5, inplace=True)\n",
       "  (drop_way): Dropout(p=0.2, inplace=True)\n",
       "  (selu): SELU(inplace=True)\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (conv1): Conv2d(1, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(32, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (GAT_layer_S): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (GAT_layer_T): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST11): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_type2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (att_proj): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST12): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST21): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_type2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (att_proj): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST22): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (pool_S): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=24, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_T): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=24, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (out_layer): Linear(in_features=160, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "196a6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS3_AASIST-L_ep100_bs24/eval_scores_cs3_lj.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21664ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in lj_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5516de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LJ EER:  2.0408163265306123\n"
     ]
    }
   ],
   "source": [
    "eer_lj = getEER(eval_score_path)\n",
    "print('LJ EER: ', eer_lj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8079b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff8c449e",
   "metadata": {},
   "source": [
    "# Libri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afc6090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_train_protocol.txt\",\n",
    "    \"eval\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri/train/\",\n",
    "    \"eval\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79ac9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "libri_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92d9ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS3_AASIST-L_ep100_bs24/eval_scores_cs3_libri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab582bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in libri_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29383bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libri EER:  4.761904761904762\n"
     ]
    }
   ],
   "source": [
    "eer_libri = getEER(eval_score_path)\n",
    "print('Libri EER: ', eer_libri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06298918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cc6c288",
   "metadata": {},
   "source": [
    "# CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c0e84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_train_protocol.txt\",\n",
    "    \"eval\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU/train/\",\n",
    "    \"eval\": \"/data/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa786379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "cmu_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52d17eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS3_AASIST-L_ep100_bs24/eval_scores_cs3_cmu.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1068f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in cmu_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a5e39d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU EER:  0.0\n"
     ]
    }
   ],
   "source": [
    "eer_cmu = getEER(eval_score_path)\n",
    "print('CMU EER: ', eer_cmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b62052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6336a36a",
   "metadata": {},
   "source": [
    "# ASVspoof 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98756edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_trial_path = Path('/data/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt')\n",
    "eval_database_path = Path('/data/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_eval/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea08a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSpoof_list1(dir_meta, is_train=False, is_eval=False):\n",
    "\n",
    "    d_meta = {}\n",
    "    file_list = []\n",
    "    with open(dir_meta, \"r\") as f:\n",
    "        l_meta = f.readlines()\n",
    "\n",
    "    if is_train:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list\n",
    "\n",
    "    elif is_eval:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, _ = line.strip().split(\" \")\n",
    "            #key = line.strip()\n",
    "            file_list.append(key)\n",
    "        return file_list\n",
    "    else:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "181de04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_eval = genSpoof_list1(dir_meta=eval_trial_path,\n",
    "                          is_train=False,\n",
    "                          is_eval=True)\n",
    "eval_set = Dataset_ASVspoof2019_devNeval(list_IDs=file_eval,\n",
    "                                         base_dir=eval_database_path)\n",
    "eval_loader = DataLoader(eval_set,\n",
    "                         batch_size=config[\"batch_size\"],\n",
    "                         shuffle=False,\n",
    "                         drop_last=False,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8fe931e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0009, 0.0008, 0.0007,  ..., 0.1776, 0.1562, 0.1233]),\n",
       " 'LA_E_2834763')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2188eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS3_AASIST-L_ep100_bs24/eval_scores_cs3_asv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ee5c6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CS3_AASIST-L_ep100_bs24/eval_scores_cs3_asv\n"
     ]
    }
   ],
   "source": [
    "trial_path = eval_trial_path\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in eval_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "print(\"Scores saved to {}\".format(eval_score_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4b594df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_lines) == len(fname_list) == len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d81b2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEER1(score_path):\n",
    "    cm_data = np.genfromtxt(score_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 2]\n",
    "    cm_scores = cm_data[:, 3].astype(float)\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "    return eer_cm * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c01fa5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASV EER:  1.729799510743923\n"
     ]
    }
   ],
   "source": [
    "eer_asv = getEER1(eval_score_path)\n",
    "print('ASV EER: ', eer_asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5cf6840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03759471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CS3_AASIST-L_ep100_bs24/eval_scores_cs3_asv\n"
     ]
    }
   ],
   "source": [
    "produce_evaluation_file(eval_loader, model, device, eval_score_path,\n",
    "                            eval_trial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50db4f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASV EER:  1.729799510743923\n"
     ]
    }
   ],
   "source": [
    "eer_asv = getEER1(eval_score_path)\n",
    "print('ASV EER: ', eer_asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0123a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d3e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
