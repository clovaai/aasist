{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f0e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "from shutil import copy\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "from data_utils import (Dataset_ASVspoof2019_train,\n",
    "                        Dataset_ASVspoof2019_devNeval, genSpoof_list_prevDbs,\n",
    "                        Dataset_train_prevDbs, Dataset_PrevDbs)\n",
    "from evaluation import calculate_tDCF_EER\n",
    "from utils import create_optimizer, seed_worker, set_seed, str_to_bool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acec9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"database_path\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/combined/\",\n",
    "#     \"asv_score_path\": \"ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.eval.gi.trl.scores.txt\",\n",
    "    \"model_path\": \"./models/weights/AASIST-L.pth\",\n",
    "    \"batch_size\": 24,\n",
    "    \"num_epochs\": 100,\n",
    "    \"loss\": \"CCE\",\n",
    "    \"track\": \"LA\",\n",
    "    \"eval_all_best\": \"True\",\n",
    "    \"eval_output\": \"eval_scores_cs1_cs1.txt\",\n",
    "    \"cudnn_deterministic_toggle\": \"True\",\n",
    "    \"cudnn_benchmark_toggle\": \"False\",\n",
    "    \"model_config\": {\n",
    "        \"architecture\": \"AASIST\",\n",
    "        \"nb_samp\": 64600,\n",
    "        \"first_conv\": 128,\n",
    "        \"filts\": [70, [1, 32], [32, 32], [32, 24], [24, 24]],\n",
    "        \"gat_dims\": [24, 32],\n",
    "        \"pool_ratios\": [0.4, 0.5, 0.7, 0.5],\n",
    "        \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n",
    "    },\n",
    "    \"optim_config\": {\n",
    "        \"optimizer\": \"adam\", \n",
    "        \"amsgrad\": \"False\",\n",
    "        \"base_lr\": 0.0001,\n",
    "        \"lr_min\": 0.000005,\n",
    "        \"betas\": [0.9, 0.999],\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"scheduler\": \"cosine\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5767dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = config[\"model_config\"]\n",
    "optim_config = config[\"optim_config\"]\n",
    "optim_config[\"epochs\"] = config[\"num_epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ced4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"eval_all_best\" not in config:\n",
    "    config[\"eval_all_best\"] = \"True\"\n",
    "if \"freq_aug\" not in config:\n",
    "    config[\"freq_aug\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c77339",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1234, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acee9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random \n",
    " \n",
    "# fin = open(\"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/combined_train_protocol.txt\", 'rb') \n",
    "# f90out = open(\"./protocols/combinedSet1_split_train.txt\", 'wb') \n",
    "# f10out = open(\"./protocols/CombinedSet1_split_dev.txt\", 'wb') \n",
    "# for line in fin: \n",
    "#     r = random.random() \n",
    "#     if r < 0.90: \n",
    "#         f90out.write(line) \n",
    "#     else: \n",
    "#         f10out.write(line) \n",
    "# fin.close() \n",
    "# f90out.close() \n",
    "# f10out.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7bbdc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/combined/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"database_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e16d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('./exp_result')\n",
    "database_path = Path(config[\"database_path\"])\n",
    "dev_trial_path = Path('./protocols/CombinedSet1_split_dev.txt')\n",
    "eval_trial_path = Path('/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/combined_test_protocol.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9051a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model related paths\n",
    "model_tag = \"{}_{}_ep{}_bs{}\".format(\n",
    "    'CS1',\n",
    "    'AASIST-L',\n",
    "    config[\"num_epochs\"], config[\"batch_size\"])\n",
    "model_tag = output_dir / model_tag\n",
    "model_save_path = model_tag / \"weights\"\n",
    "eval_score_path = model_tag / config[\"eval_output\"]\n",
    "writer = SummaryWriter(model_tag)\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "346e6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_config: Dict, device: torch.device):\n",
    "    \"\"\"Define DNN model architecture\"\"\"\n",
    "    module = import_module(\"models.{}\".format(model_config[\"architecture\"]))\n",
    "    _model = getattr(module, \"Model\")\n",
    "    model = _model(model_config).to(device)\n",
    "    nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "    print(\"no. model params:{}\".format(nb_params))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cfb5f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "no. model params:85306\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: {}\".format(device))\n",
    "if device == \"cpu\":\n",
    "    raise ValueError(\"GPU not detected!\")\n",
    "\n",
    "# define model architecture\n",
    "model = get_model(model_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ebe594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/combined')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52027e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. training files: 2468\n",
      "no. validation files: 302\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Make PyTorch DataLoaders for train / developement / evaluation\"\"\"\n",
    "\n",
    "trn_database_path = database_path / 'Train'\n",
    "dev_database_path = database_path / 'Train'\n",
    "eval_database_path = database_path / 'Test'\n",
    "\n",
    "trn_list_path = Path('./protocols/combinedSet1_split_train.txt')\n",
    "dev_trial_path = './protocols/CombinedSet1_split_dev.txt'\n",
    "eval_trial_path = '/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/combined_test_protocol.txt'\n",
    "d_label_trn, file_train = genSpoof_list_prevDbs(dir_meta=trn_list_path,\n",
    "                                        is_train=True,\n",
    "                                        is_eval=False)\n",
    "print(\"no. training files:\", len(file_train))\n",
    "\n",
    "train_set = Dataset_train_prevDbs(list_IDs=file_train,\n",
    "                                       labels=d_label_trn,\n",
    "                                       base_dir=trn_database_path)\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(1234)\n",
    "trn_loader = DataLoader(train_set,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        pin_memory=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=gen)\n",
    "\n",
    "_, file_dev = genSpoof_list_prevDbs(dir_meta=dev_trial_path,\n",
    "                            is_train=False,\n",
    "                            is_eval=False)\n",
    "print(\"no. validation files:\", len(file_dev))\n",
    "\n",
    "dev_set = Dataset_PrevDbs(list_IDs=file_dev,\n",
    "                                        base_dir=dev_database_path)\n",
    "dev_loader = DataLoader(dev_set,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "file_eval = genSpoof_list_prevDbs(dir_meta=eval_trial_path,\n",
    "                          is_train=False,\n",
    "                          is_eval=True)\n",
    "eval_set = Dataset_PrevDbs(list_IDs=file_eval,\n",
    "                                         base_dir=eval_database_path)\n",
    "eval_loader = DataLoader(eval_set,\n",
    "                         batch_size=config[\"batch_size\"],\n",
    "                         shuffle=False,\n",
    "                         drop_last=False,\n",
    "                         pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6950b1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get optimizer and scheduler\n",
    "optim_config[\"steps_per_epoch\"] = len(trn_loader)\n",
    "optimizer, scheduler = create_optimizer(model.parameters(), optim_config)\n",
    "optimizer_swa = SWA(optimizer)\n",
    "\n",
    "best_dev_eer = 1.\n",
    "best_eval_eer = 100.\n",
    "best_dev_tdcf = 0.05\n",
    "best_eval_tdcf = 1.\n",
    "n_swa_update = 0  # number of snapshots of model to use in SWA\n",
    "f_log = open(model_tag / \"metric_log.txt\", \"a\")\n",
    "f_log.write(\"=\" * 5 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d83005a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('exp_result/CS1_AASIST-L_ep100_bs24')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "545577c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory for metric logging\n",
    "metric_path = model_tag / \"metrics\"\n",
    "os.makedirs(metric_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4bad5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            utt_id, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} \\n\".format(utt_id, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    trn_loader: DataLoader,\n",
    "    model,\n",
    "    optim: Union[torch.optim.SGD, torch.optim.Adam],\n",
    "    device: torch.device,\n",
    "    scheduler: torch.optim.lr_scheduler,\n",
    "    config: argparse.Namespace):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    running_loss = 0\n",
    "    num_total = 0.0\n",
    "    ii = 0\n",
    "    model.train()\n",
    "\n",
    "    # set objective (Loss) functions\n",
    "    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    for batch_x, batch_y in trn_loader:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        ii += 1\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        _, batch_out = model(batch_x, Freq_aug=str_to_bool(config[\"freq_aug\"]))\n",
    "        batch_loss = criterion(batch_out, batch_y)\n",
    "        running_loss += batch_loss.item() * batch_size\n",
    "        optim.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if config[\"optim_config\"][\"scheduler\"] in [\"cosine\", \"keras_decay\"]:\n",
    "            scheduler.step()\n",
    "        elif scheduler is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"scheduler error, got:{}\".format(scheduler))\n",
    "\n",
    "    running_loss /= num_total\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "890c7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluation import compute_eer\n",
    "def getEER(score_path):\n",
    "    cm_data = np.genfromtxt(score_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 1]\n",
    "    cm_scores = cm_data[:, 2].astype(float)\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "    return eer_cm * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9753dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training epoch000\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.49063, dev_eer: 47.351\n",
      "Start training epoch001\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.42969, dev_eer: 45.364\n",
      "Start training epoch002\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.41358, dev_eer: 44.702\n",
      "Start training epoch003\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.40285, dev_eer: 37.417\n",
      "Start training epoch004\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.39072, dev_eer: 33.443\n",
      "Start training epoch005\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.35434, dev_eer: 32.118\n",
      "Start training epoch006\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.34652, dev_eer: 28.807\n",
      "Start training epoch007\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.31282, dev_eer: 26.158\n",
      "Start training epoch008\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.31025, dev_eer: 26.158\n",
      "Start training epoch009\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.28079, dev_eer: 21.855\n",
      "Start training epoch010\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.26359, dev_eer: 24.833\n",
      "Start training epoch011\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.23833, dev_eer: 19.206\n",
      "Start training epoch012\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.22426, dev_eer: 17.882\n",
      "Start training epoch013\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.20759, dev_eer: 13.246\n",
      "Start training epoch014\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.19929, dev_eer: 12.583\n",
      "Start training epoch015\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.17557, dev_eer: 9.272\n",
      "Start training epoch016\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.16483, dev_eer: 13.908\n",
      "Start training epoch017\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.15227, dev_eer: 8.610\n",
      "Start training epoch018\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.14233, dev_eer: 7.947\n",
      "Start training epoch019\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.13325, dev_eer: 4.636\n",
      "Start training epoch020\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.12388, dev_eer: 11.259\n",
      "Start training epoch021\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.11292, dev_eer: 7.947\n",
      "Start training epoch022\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.10256, dev_eer: 3.974\n",
      "Start training epoch023\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.09939, dev_eer: 3.974\n",
      "Start training epoch024\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.08296, dev_eer: 1.325\n",
      "Start training epoch025\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.08660, dev_eer: 1.325\n",
      "Start training epoch026\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06370, dev_eer: 2.649\n",
      "Start training epoch027\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06087, dev_eer: 1.325\n",
      "Start training epoch028\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04700, dev_eer: 1.325\n",
      "Start training epoch029\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04730, dev_eer: 2.649\n",
      "Start training epoch030\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06967, dev_eer: 0.662\n",
      "best model find at epoch 30\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch030, best eer, 1.4706%\n",
      "Saving epoch 30 for swa\n",
      "Start training epoch031\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06861, dev_eer: 0.000\n",
      "best model find at epoch 31\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch031, best eer, 0.7353%\n",
      "Saving epoch 31 for swa\n",
      "Start training epoch032\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04507, dev_eer: 1.325\n",
      "Start training epoch033\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03480, dev_eer: 0.662\n",
      "Start training epoch034\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03412, dev_eer: 0.000\n",
      "best model find at epoch 34\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch034, best eer, 0.0000%\n",
      "Saving epoch 34 for swa\n",
      "Start training epoch035\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02945, dev_eer: 0.662\n",
      "Start training epoch036\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03482, dev_eer: 1.325\n",
      "Start training epoch037\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03243, dev_eer: 0.000\n",
      "best model find at epoch 37\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch037, \n",
      "Saving epoch 37 for swa\n",
      "Start training epoch038\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04188, dev_eer: 1.987\n",
      "Start training epoch039\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04724, dev_eer: 1.325\n",
      "Start training epoch040\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02250, dev_eer: 0.000\n",
      "best model find at epoch 40\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch040, \n",
      "Saving epoch 40 for swa\n",
      "Start training epoch041\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02781, dev_eer: 0.000\n",
      "best model find at epoch 41\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch041, \n",
      "Saving epoch 41 for swa\n",
      "Start training epoch042\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03004, dev_eer: 0.000\n",
      "best model find at epoch 42\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch042, \n",
      "Saving epoch 42 for swa\n",
      "Start training epoch043\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02488, dev_eer: 0.000\n",
      "best model find at epoch 43\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch043, \n",
      "Saving epoch 43 for swa\n",
      "Start training epoch044\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03140, dev_eer: 0.000\n",
      "best model find at epoch 44\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch044, \n",
      "Saving epoch 44 for swa\n",
      "Start training epoch045\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02100, dev_eer: 0.662\n",
      "Start training epoch046\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03155, dev_eer: 1.987\n",
      "Start training epoch047\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02630, dev_eer: 0.000\n",
      "best model find at epoch 47\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch047, \n",
      "Saving epoch 47 for swa\n",
      "Start training epoch048\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02057, dev_eer: 0.000\n",
      "best model find at epoch 48\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch048, \n",
      "Saving epoch 48 for swa\n",
      "Start training epoch049\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02029, dev_eer: 0.000\n",
      "best model find at epoch 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch049, \n",
      "Saving epoch 49 for swa\n",
      "Start training epoch050\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02293, dev_eer: 0.000\n",
      "best model find at epoch 50\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch050, \n",
      "Saving epoch 50 for swa\n",
      "Start training epoch051\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01592, dev_eer: 0.000\n",
      "best model find at epoch 51\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch051, \n",
      "Saving epoch 51 for swa\n",
      "Start training epoch052\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01361, dev_eer: 0.662\n",
      "Start training epoch053\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02865, dev_eer: 0.000\n",
      "best model find at epoch 53\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch053, \n",
      "Saving epoch 53 for swa\n",
      "Start training epoch054\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01948, dev_eer: 0.000\n",
      "best model find at epoch 54\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch054, \n",
      "Saving epoch 54 for swa\n",
      "Start training epoch055\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01770, dev_eer: 0.000\n",
      "best model find at epoch 55\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch055, \n",
      "Saving epoch 55 for swa\n",
      "Start training epoch056\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01091, dev_eer: 0.000\n",
      "best model find at epoch 56\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch056, \n",
      "Saving epoch 56 for swa\n",
      "Start training epoch057\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00994, dev_eer: 0.000\n",
      "best model find at epoch 57\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch057, \n",
      "Saving epoch 57 for swa\n",
      "Start training epoch058\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01284, dev_eer: 0.000\n",
      "best model find at epoch 58\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch058, \n",
      "Saving epoch 58 for swa\n",
      "Start training epoch059\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01429, dev_eer: 0.000\n",
      "best model find at epoch 59\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch059, \n",
      "Saving epoch 59 for swa\n",
      "Start training epoch060\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01554, dev_eer: 0.000\n",
      "best model find at epoch 60\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch060, \n",
      "Saving epoch 60 for swa\n",
      "Start training epoch061\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01339, dev_eer: 0.000\n",
      "best model find at epoch 61\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch061, \n",
      "Saving epoch 61 for swa\n",
      "Start training epoch062\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01144, dev_eer: 0.000\n",
      "best model find at epoch 62\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch062, \n",
      "Saving epoch 62 for swa\n",
      "Start training epoch063\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00926, dev_eer: 0.000\n",
      "best model find at epoch 63\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch063, \n",
      "Saving epoch 63 for swa\n",
      "Start training epoch064\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01146, dev_eer: 0.000\n",
      "best model find at epoch 64\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch064, \n",
      "Saving epoch 64 for swa\n",
      "Start training epoch065\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01020, dev_eer: 0.000\n",
      "best model find at epoch 65\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch065, \n",
      "Saving epoch 65 for swa\n",
      "Start training epoch066\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01105, dev_eer: 0.662\n",
      "Start training epoch067\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01362, dev_eer: 0.000\n",
      "best model find at epoch 67\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch067, \n",
      "Saving epoch 67 for swa\n",
      "Start training epoch068\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01242, dev_eer: 0.000\n",
      "best model find at epoch 68\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch068, \n",
      "Saving epoch 68 for swa\n",
      "Start training epoch069\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00550, dev_eer: 0.000\n",
      "best model find at epoch 69\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch069, \n",
      "Saving epoch 69 for swa\n",
      "Start training epoch070\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01063, dev_eer: 0.000\n",
      "best model find at epoch 70\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch070, \n",
      "Saving epoch 70 for swa\n",
      "Start training epoch071\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00778, dev_eer: 0.000\n",
      "best model find at epoch 71\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch071, \n",
      "Saving epoch 71 for swa\n",
      "Start training epoch072\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01169, dev_eer: 0.000\n",
      "best model find at epoch 72\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch072, \n",
      "Saving epoch 72 for swa\n",
      "Start training epoch073\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01050, dev_eer: 0.000\n",
      "best model find at epoch 73\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch073, \n",
      "Saving epoch 73 for swa\n",
      "Start training epoch074\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00894, dev_eer: 0.000\n",
      "best model find at epoch 74\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch074, \n",
      "Saving epoch 74 for swa\n",
      "Start training epoch075\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00954, dev_eer: 0.000\n",
      "best model find at epoch 75\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch075, \n",
      "Saving epoch 75 for swa\n",
      "Start training epoch076\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00636, dev_eer: 0.000\n",
      "best model find at epoch 76\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch076, \n",
      "Saving epoch 76 for swa\n",
      "Start training epoch077\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00589, dev_eer: 0.000\n",
      "best model find at epoch 77\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch077, \n",
      "Saving epoch 77 for swa\n",
      "Start training epoch078\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00971, dev_eer: 0.000\n",
      "best model find at epoch 78\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch078, \n",
      "Saving epoch 78 for swa\n",
      "Start training epoch079\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00683, dev_eer: 0.000\n",
      "best model find at epoch 79\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch079, \n",
      "Saving epoch 79 for swa\n",
      "Start training epoch080\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01033, dev_eer: 0.000\n",
      "best model find at epoch 80\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch080, \n",
      "Saving epoch 80 for swa\n",
      "Start training epoch081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00892, dev_eer: 0.000\n",
      "best model find at epoch 81\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch081, \n",
      "Saving epoch 81 for swa\n",
      "Start training epoch082\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00846, dev_eer: 0.000\n",
      "best model find at epoch 82\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch082, \n",
      "Saving epoch 82 for swa\n",
      "Start training epoch083\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00630, dev_eer: 0.000\n",
      "best model find at epoch 83\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch083, \n",
      "Saving epoch 83 for swa\n",
      "Start training epoch084\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00481, dev_eer: 0.000\n",
      "best model find at epoch 84\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch084, \n",
      "Saving epoch 84 for swa\n",
      "Start training epoch085\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00557, dev_eer: 0.000\n",
      "best model find at epoch 85\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch085, \n",
      "Saving epoch 85 for swa\n",
      "Start training epoch086\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00816, dev_eer: 0.000\n",
      "best model find at epoch 86\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch086, \n",
      "Saving epoch 86 for swa\n",
      "Start training epoch087\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00479, dev_eer: 0.000\n",
      "best model find at epoch 87\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch087, \n",
      "Saving epoch 87 for swa\n",
      "Start training epoch088\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00630, dev_eer: 0.000\n",
      "best model find at epoch 88\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch088, \n",
      "Saving epoch 88 for swa\n",
      "Start training epoch089\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00823, dev_eer: 0.000\n",
      "best model find at epoch 89\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch089, \n",
      "Saving epoch 89 for swa\n",
      "Start training epoch090\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00613, dev_eer: 0.000\n",
      "best model find at epoch 90\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch090, \n",
      "Saving epoch 90 for swa\n",
      "Start training epoch091\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00962, dev_eer: 0.000\n",
      "best model find at epoch 91\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch091, \n",
      "Saving epoch 91 for swa\n",
      "Start training epoch092\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01167, dev_eer: 0.000\n",
      "best model find at epoch 92\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch092, \n",
      "Saving epoch 92 for swa\n",
      "Start training epoch093\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01029, dev_eer: 0.000\n",
      "best model find at epoch 93\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch093, \n",
      "Saving epoch 93 for swa\n",
      "Start training epoch094\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00429, dev_eer: 0.000\n",
      "best model find at epoch 94\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch094, \n",
      "Saving epoch 94 for swa\n",
      "Start training epoch095\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00938, dev_eer: 0.000\n",
      "best model find at epoch 95\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch095, \n",
      "Saving epoch 95 for swa\n",
      "Start training epoch096\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00864, dev_eer: 0.000\n",
      "best model find at epoch 96\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch096, \n",
      "Saving epoch 96 for swa\n",
      "Start training epoch097\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00582, dev_eer: 0.000\n",
      "best model find at epoch 97\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch097, \n",
      "Saving epoch 97 for swa\n",
      "Start training epoch098\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00590, dev_eer: 0.000\n",
      "best model find at epoch 98\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch098, \n",
      "Saving epoch 98 for swa\n",
      "Start training epoch099\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.00497, dev_eer: 0.000\n",
      "best model find at epoch 99\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "epoch099, \n",
      "Saving epoch 99 for swa\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    print(\"Start training epoch{:03d}\".format(epoch))\n",
    "    running_loss = train_epoch(trn_loader, model, optimizer, device,\n",
    "                               scheduler, config)\n",
    "    produce_evaluation_file(dev_loader, model, device,\n",
    "                            metric_path/\"dev_score.txt\", dev_trial_path)\n",
    "    dev_eer = getEER(metric_path/\"dev_score.txt\")\n",
    "    print(\"DONE.\\nLoss:{:.5f}, dev_eer: {:.3f}\".format(\n",
    "        running_loss, dev_eer))\n",
    "    writer.add_scalar(\"loss\", running_loss, epoch)\n",
    "    writer.add_scalar(\"dev_eer\", dev_eer, epoch)\n",
    "\n",
    "    if best_dev_eer >= dev_eer:\n",
    "        print(\"best model find at epoch\", epoch)\n",
    "        best_dev_eer = dev_eer\n",
    "        torch.save(model.state_dict(),\n",
    "                   model_save_path / \"epoch_{}_{:03.3f}.pth\".format(epoch, dev_eer))\n",
    "\n",
    "        # do evaluation whenever best model is renewed\n",
    "        if str_to_bool(config[\"eval_all_best\"]):\n",
    "            produce_evaluation_file(eval_loader, model, device,\n",
    "                                    eval_score_path, eval_trial_path)\n",
    "            dev_eer = getEER(metric_path/\"dev_score.txt\")\n",
    "            eval_eer = getEER(eval_score_path)\n",
    "\n",
    "            log_text = \"epoch{:03d}, \".format(epoch)\n",
    "            if eval_eer < best_eval_eer:\n",
    "                log_text += \"best eer, {:.4f}%\".format(eval_eer)\n",
    "                best_eval_eer = eval_eer\n",
    "                torch.save(model.state_dict(),\n",
    "                           model_save_path / \"best.pth\")\n",
    "            if len(log_text) > 0:\n",
    "                print(log_text)\n",
    "                f_log.write(log_text + \"\\n\")\n",
    "\n",
    "        print(\"Saving epoch {} for swa\".format(epoch))\n",
    "        optimizer_swa.update_swa()\n",
    "        n_swa_update += 1\n",
    "    writer.add_scalar(\"best_dev_eer\", best_dev_eer, epoch)\n",
    "    writer.add_scalar(\"best_dev_tdcf\", best_dev_tdcf, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "805dd57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start final evaluation\n",
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cs1.txt\n",
      "Exp FIN. EER: 0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Start final evaluation\")\n",
    "epoch += 1\n",
    "if n_swa_update > 0:\n",
    "    optimizer_swa.swap_swa_sgd()\n",
    "    optimizer_swa.bn_update(trn_loader, model, device=device)\n",
    "produce_evaluation_file(eval_loader, model, device, eval_score_path,\n",
    "                        eval_trial_path)\n",
    "eval_eer = getEER(eval_score_path)\n",
    "f_log = open(model_tag / \"metric_log.txt\", \"a\")\n",
    "f_log.write(\"=\" * 5 + \"\\n\")\n",
    "f_log.write(\"EER: {:.3f}\".format(eval_eer))\n",
    "f_log.close()\n",
    "\n",
    "torch.save(model.state_dict(),\n",
    "           model_save_path / \"swa.pth\")\n",
    "\n",
    "if eval_eer <= best_eval_eer:\n",
    "    best_eval_eer = eval_eer\n",
    "# if eval_tdcf <= best_eval_tdcf:\n",
    "#     best_eval_tdcf = eval_tdcf\n",
    "    torch.save(model.state_dict(),\n",
    "               model_save_path / \"best.pth\")\n",
    "print(\"Exp FIN. EER: {:.3f}\".format(\n",
    "    best_eval_eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3faad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97fd5fb0",
   "metadata": {},
   "source": [
    "# LJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afb1802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/lj_train_protocol.txt\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/lj_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/LJ/train/\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/LJ/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b98f5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "lj_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d69cd1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv_time): CONV()\n",
       "  (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.5, inplace=True)\n",
       "  (drop_way): Dropout(p=0.2, inplace=True)\n",
       "  (selu): SELU(inplace=True)\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (conv1): Conv2d(1, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(32, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (GAT_layer_S): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (GAT_layer_T): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST11): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_type2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (att_proj): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST12): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST21): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_type2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (att_proj): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST22): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (pool_S): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=24, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_T): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=24, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (out_layer): Linear(in_features=160, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "779aa967",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_lj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "827c0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in lj_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1ccd53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LJ EER:  0.0\n"
     ]
    }
   ],
   "source": [
    "eer_lj = getEER(eval_score_path)\n",
    "print('LJ EER: ', eer_lj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec78e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38623b03",
   "metadata": {},
   "source": [
    "# Libri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c1074f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_train_protocol.txt\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri/train/\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aec49eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "libri_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b902a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_libri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f28cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in libri_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db5e53b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libri EER:  0.0\n"
     ]
    }
   ],
   "source": [
    "eer_libri = getEER(eval_score_path)\n",
    "print('Libri EER: ', eer_libri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90560955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3b5f104",
   "metadata": {},
   "source": [
    "# CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0795fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_train_protocol.txt\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU/train/\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3af668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "cmu_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f678f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_cmu.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07ab426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in cmu_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "142416a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU EER:  0.0\n"
     ]
    }
   ],
   "source": [
    "eer_cmu = getEER(eval_score_path)\n",
    "print('CMU EER: ', eer_cmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55db8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6af267b",
   "metadata": {},
   "source": [
    "# ASVspoof 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e42aa6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_trial_path = Path('/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt')\n",
    "eval_database_path = Path('/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_eval/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63c143bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSpoof_list1(dir_meta, is_train=False, is_eval=False):\n",
    "\n",
    "    d_meta = {}\n",
    "    file_list = []\n",
    "    with open(dir_meta, \"r\") as f:\n",
    "        l_meta = f.readlines()\n",
    "\n",
    "    if is_train:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list\n",
    "\n",
    "    elif is_eval:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, _ = line.strip().split(\" \")\n",
    "            #key = line.strip()\n",
    "            file_list.append(key)\n",
    "        return file_list\n",
    "    else:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22b8418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_eval = genSpoof_list1(dir_meta=eval_trial_path,\n",
    "                          is_train=False,\n",
    "                          is_eval=True)\n",
    "eval_set = Dataset_ASVspoof2019_devNeval(list_IDs=file_eval,\n",
    "                                         base_dir=eval_database_path)\n",
    "eval_loader = DataLoader(eval_set,\n",
    "                         batch_size=config[\"batch_size\"],\n",
    "                         shuffle=False,\n",
    "                         drop_last=False,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38b26656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0009, 0.0008, 0.0007,  ..., 0.1776, 0.1562, 0.1233]),\n",
       " 'LA_E_2834763')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dd4eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_asv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f96a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_asv\n"
     ]
    }
   ],
   "source": [
    "trial_path = eval_trial_path\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in eval_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "print(\"Scores saved to {}\".format(eval_score_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d477614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_lines) == len(fname_list) == len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68bdd34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEER1(score_path):\n",
    "    cm_data = np.genfromtxt(score_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 2]\n",
    "    cm_scores = cm_data[:, 3].astype(float)\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "    return eer_cm * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f24683d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASV EER:  36.12318554874639\n"
     ]
    }
   ],
   "source": [
    "eer_asv = getEER1(eval_score_path)\n",
    "print('ASV EER: ', eer_asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "376ebe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a498e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/CS1_AASIST-L_ep100_bs24/eval_scores_cs1_asv\n"
     ]
    }
   ],
   "source": [
    "produce_evaluation_file(eval_loader, model, device, eval_score_path,\n",
    "                            eval_trial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84aa6454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASV EER:  36.12318554874639\n"
     ]
    }
   ],
   "source": [
    "eer_asv = getEER1(eval_score_path)\n",
    "print('ASV EER: ', eer_asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01aa8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
