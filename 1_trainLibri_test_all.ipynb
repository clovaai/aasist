{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e41952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "from shutil import copy\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "from data_utils import (Dataset_ASVspoof2019_train,\n",
    "                        Dataset_ASVspoof2019_devNeval, genSpoof_list_prevDbs,\n",
    "                        Dataset_train_prevDbs, Dataset_PrevDbs)\n",
    "from evaluation import calculate_tDCF_EER\n",
    "from utils import create_optimizer, seed_worker, set_seed, str_to_bool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "221bbdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"database_path\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri/\",\n",
    "#     \"asv_score_path\": \"ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.eval.gi.trl.scores.txt\",\n",
    "    \"model_path\": \"./models/weights/AASIST-L.pth\",\n",
    "    \"batch_size\": 24,\n",
    "    \"num_epochs\": 100,\n",
    "    \"loss\": \"CCE\",\n",
    "    \"track\": \"LA\",\n",
    "    \"eval_all_best\": \"True\",\n",
    "    \"eval_output\": \"eval_scores_libri_libri.txt\",\n",
    "    \"cudnn_deterministic_toggle\": \"True\",\n",
    "    \"cudnn_benchmark_toggle\": \"False\",\n",
    "    \"model_config\": {\n",
    "        \"architecture\": \"AASIST\",\n",
    "        \"nb_samp\": 64600,\n",
    "        \"first_conv\": 128,\n",
    "        \"filts\": [70, [1, 32], [32, 32], [32, 24], [24, 24]],\n",
    "        \"gat_dims\": [24, 32],\n",
    "        \"pool_ratios\": [0.4, 0.5, 0.7, 0.5],\n",
    "        \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n",
    "    },\n",
    "    \"optim_config\": {\n",
    "        \"optimizer\": \"adam\", \n",
    "        \"amsgrad\": \"False\",\n",
    "        \"base_lr\": 0.0001,\n",
    "        \"lr_min\": 0.000005,\n",
    "        \"betas\": [0.9, 0.999],\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"scheduler\": \"cosine\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "500701e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = config[\"model_config\"]\n",
    "optim_config = config[\"optim_config\"]\n",
    "optim_config[\"epochs\"] = config[\"num_epochs\"]\n",
    "# track = config[\"track\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8c5c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"eval_all_best\" not in config:\n",
    "    config[\"eval_all_best\"] = \"True\"\n",
    "if \"freq_aug\" not in config:\n",
    "    config[\"freq_aug\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eefd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1234, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ebdcec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random \n",
    " \n",
    "# fin = open(\"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_train_protocol.txt\", 'rb') \n",
    "# f90out = open(\"./protocols/libri_split_train.txt\", 'wb') \n",
    "# f10out = open(\"./protocols/libri_split_dev.txt\", 'wb') \n",
    "# for line in fin: \n",
    "#     r = random.random() \n",
    "#     if r < 0.90: \n",
    "#         f90out.write(line) \n",
    "#     else: \n",
    "#         f10out.write(line) \n",
    "# fin.close() \n",
    "# f90out.close() \n",
    "# f10out.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7ed44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2058a391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"database_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b9a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('./exp_result')\n",
    "# prefix_2019 = \"cmu.{}\".format(track)\n",
    "database_path = Path(config[\"database_path\"])\n",
    "dev_trial_path = Path('./protocols/libri_split_dev.txt')\n",
    "# (database_path /\n",
    "#                     \"ASVspoof2019_{}_cm_protocols/{}.cm.dev.trl.txt\".format(\n",
    "#                         track, prefix_2019))\n",
    "eval_trial_path = Path('/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_test_protocol.txt')\n",
    "# (\n",
    "#     database_path /\n",
    "#     \"ASVspoof2019_{}_cm_protocols/{}.cm.eval.trl.txt\".format(\n",
    "#         track, prefix_2019))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1608046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model related paths\n",
    "model_tag = \"{}_{}_ep{}_bs{}\".format(\n",
    "    'LIBRI',\n",
    "    'AASIST-L',\n",
    "    config[\"num_epochs\"], config[\"batch_size\"])\n",
    "# if args.comment:\n",
    "#     model_tag = model_tag + \"_{}\".format(args.comment)\n",
    "model_tag = output_dir / model_tag\n",
    "model_save_path = model_tag / \"weights\"\n",
    "eval_score_path = model_tag / config[\"eval_output\"]\n",
    "writer = SummaryWriter(model_tag)\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "# copy(args.config, model_tag / \"config.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31fed224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_config: Dict, device: torch.device):\n",
    "    \"\"\"Define DNN model architecture\"\"\"\n",
    "    module = import_module(\"models.{}\".format(model_config[\"architecture\"]))\n",
    "    _model = getattr(module, \"Model\")\n",
    "    model = _model(model_config).to(device)\n",
    "    nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "    print(\"no. model params:{}\".format(nb_params))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d442260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "no. model params:85306\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: {}\".format(device))\n",
    "if device == \"cpu\":\n",
    "    raise ValueError(\"GPU not detected!\")\n",
    "\n",
    "# define model architecture\n",
    "model = get_model(model_config, device)\n",
    "\n",
    "# # define dataloaders\n",
    "# trn_loader, dev_loader, eval_loader = get_loader(\n",
    "#     database_path, 1234, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bebddba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/Libri')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8a1640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. training files: 668\n",
      "no. validation files: 90\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Make PyTorch DataLoaders for train / developement / evaluation\"\"\"\n",
    "# track = config[\"track\"]\n",
    "# prefix_2019 = \"ASVspoof2019.{}\".format(track)\n",
    "\n",
    "trn_database_path = database_path / 'train'#\"ASVspoof2019_{}_train/\".format(track)\n",
    "dev_database_path = database_path / 'train'#\"ASVspoof2019_{}_dev/\".format(track)\n",
    "eval_database_path = database_path / 'test'#\"ASVspoof2019_{}_eval/\".format(track)\n",
    "\n",
    "trn_list_path = Path('./protocols/libri_split_train.txt')\n",
    "# (database_path /\n",
    "#                  \"ASVspoof2019_{}_cm_protocols/{}.cm.train.trn.txt\".format(\n",
    "#                      track, prefix_2019))\n",
    "dev_trial_path = './protocols/libri_split_dev.txt'\n",
    "# (database_path /\n",
    "#                   \"ASVspoof2019_{}_cm_protocols/{}.cm.dev.trl.txt\".format(\n",
    "#                       track, prefix_2019))\n",
    "eval_trial_path = '/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/libri_test_protocol.txt'\n",
    "# (\n",
    "#     database_path /\n",
    "#     \"ASVspoof2019_{}_cm_protocols/{}.cm.eval.trl.txt\".format(\n",
    "#         track, prefix_2019))\n",
    "\n",
    "d_label_trn, file_train = genSpoof_list_prevDbs(dir_meta=trn_list_path,\n",
    "                                        is_train=True,\n",
    "                                        is_eval=False)\n",
    "print(\"no. training files:\", len(file_train))\n",
    "\n",
    "train_set = Dataset_train_prevDbs(list_IDs=file_train,\n",
    "                                       labels=d_label_trn,\n",
    "                                       base_dir=trn_database_path)\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(1234)\n",
    "trn_loader = DataLoader(train_set,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        pin_memory=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=gen)\n",
    "\n",
    "_, file_dev = genSpoof_list_prevDbs(dir_meta=dev_trial_path,\n",
    "                            is_train=False,\n",
    "                            is_eval=False)\n",
    "print(\"no. validation files:\", len(file_dev))\n",
    "\n",
    "dev_set = Dataset_PrevDbs(list_IDs=file_dev,\n",
    "                                        base_dir=dev_database_path)\n",
    "dev_loader = DataLoader(dev_set,\n",
    "                        batch_size=config[\"batch_size\"],\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "file_eval = genSpoof_list_prevDbs(dir_meta=eval_trial_path,\n",
    "                          is_train=False,\n",
    "                          is_eval=True)\n",
    "eval_set = Dataset_PrevDbs(list_IDs=file_eval,\n",
    "                                         base_dir=eval_database_path)\n",
    "eval_loader = DataLoader(eval_set,\n",
    "                         batch_size=config[\"batch_size\"],\n",
    "                         shuffle=False,\n",
    "                         drop_last=False,\n",
    "                         pin_memory=True)\n",
    "\n",
    "# return trn_loader, dev_loader, eval_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea35caa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get optimizer and scheduler\n",
    "optim_config[\"steps_per_epoch\"] = len(trn_loader)\n",
    "optimizer, scheduler = create_optimizer(model.parameters(), optim_config)\n",
    "optimizer_swa = SWA(optimizer)\n",
    "\n",
    "best_dev_eer = 1.\n",
    "best_eval_eer = 100.\n",
    "best_dev_tdcf = 0.05\n",
    "best_eval_tdcf = 1.\n",
    "n_swa_update = 0  # number of snapshots of model to use in SWA\n",
    "f_log = open(model_tag / \"metric_log.txt\", \"a\")\n",
    "f_log.write(\"=\" * 5 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03184619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('exp_result/LIBRI_AASIST-L_ep100_bs24')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddc9d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory for metric logging\n",
    "metric_path = model_tag / \"metrics\"\n",
    "os.makedirs(metric_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b0d8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            utt_id, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} \\n\".format(utt_id, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    trn_loader: DataLoader,\n",
    "    model,\n",
    "    optim: Union[torch.optim.SGD, torch.optim.Adam],\n",
    "    device: torch.device,\n",
    "    scheduler: torch.optim.lr_scheduler,\n",
    "    config: argparse.Namespace):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    running_loss = 0\n",
    "    num_total = 0.0\n",
    "    ii = 0\n",
    "    model.train()\n",
    "\n",
    "    # set objective (Loss) functions\n",
    "    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    for batch_x, batch_y in trn_loader:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        ii += 1\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        _, batch_out = model(batch_x, Freq_aug=str_to_bool(config[\"freq_aug\"]))\n",
    "        batch_loss = criterion(batch_out, batch_y)\n",
    "        running_loss += batch_loss.item() * batch_size\n",
    "        optim.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if config[\"optim_config\"][\"scheduler\"] in [\"cosine\", \"keras_decay\"]:\n",
    "            scheduler.step()\n",
    "        elif scheduler is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"scheduler error, got:{}\".format(scheduler))\n",
    "\n",
    "    running_loss /= num_total\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a615ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluation import compute_eer\n",
    "def getEER(score_path):\n",
    "    cm_data = np.genfromtxt(score_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 1]\n",
    "    cm_scores = cm_data[:, 2].astype(float)\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "    return eer_cm * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a19368f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training epoch000\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04352, dev_eer: 4.464\n",
      "Start training epoch001\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03661, dev_eer: 4.464\n",
      "Start training epoch002\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04156, dev_eer: 4.464\n",
      "Start training epoch003\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04593, dev_eer: 4.464\n",
      "Start training epoch004\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03395, dev_eer: 4.464\n",
      "Start training epoch005\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03996, dev_eer: 4.464\n",
      "Start training epoch006\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04204, dev_eer: 4.464\n",
      "Start training epoch007\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04340, dev_eer: 4.464\n",
      "Start training epoch008\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03285, dev_eer: 4.464\n",
      "Start training epoch009\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04329, dev_eer: 4.464\n",
      "Start training epoch010\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03427, dev_eer: 4.464\n",
      "Start training epoch011\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03756, dev_eer: 2.232\n",
      "Start training epoch012\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03809, dev_eer: 4.464\n",
      "Start training epoch013\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03381, dev_eer: 4.464\n",
      "Start training epoch014\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04312, dev_eer: 4.464\n",
      "Start training epoch015\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04396, dev_eer: 4.464\n",
      "Start training epoch016\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03149, dev_eer: 4.464\n",
      "Start training epoch017\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04046, dev_eer: 4.464\n",
      "Start training epoch018\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04306, dev_eer: 4.464\n",
      "Start training epoch019\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04578, dev_eer: 4.464\n",
      "Start training epoch020\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.05501, dev_eer: 4.464\n",
      "Start training epoch021\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04137, dev_eer: 4.464\n",
      "Start training epoch022\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03471, dev_eer: 4.464\n",
      "Start training epoch023\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04617, dev_eer: 4.464\n",
      "Start training epoch024\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03896, dev_eer: 4.464\n",
      "Start training epoch025\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04194, dev_eer: 4.464\n",
      "Start training epoch026\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03495, dev_eer: 4.464\n",
      "Start training epoch027\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02678, dev_eer: 4.464\n",
      "Start training epoch028\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03134, dev_eer: 4.464\n",
      "Start training epoch029\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02887, dev_eer: 2.232\n",
      "Start training epoch030\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03324, dev_eer: 4.464\n",
      "Start training epoch031\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03447, dev_eer: 4.464\n",
      "Start training epoch032\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02992, dev_eer: 4.464\n",
      "Start training epoch033\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03241, dev_eer: 2.232\n",
      "Start training epoch034\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03498, dev_eer: 4.464\n",
      "Start training epoch035\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04047, dev_eer: 4.464\n",
      "Start training epoch036\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03692, dev_eer: 2.232\n",
      "Start training epoch037\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03926, dev_eer: 2.232\n",
      "Start training epoch038\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04361, dev_eer: 6.696\n",
      "Start training epoch039\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06336, dev_eer: 4.464\n",
      "Start training epoch040\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04520, dev_eer: 9.970\n",
      "Start training epoch041\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.06294, dev_eer: 4.464\n",
      "Start training epoch042\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04025, dev_eer: 2.232\n",
      "Start training epoch043\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04471, dev_eer: 2.232\n",
      "Start training epoch044\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03412, dev_eer: 2.232\n",
      "Start training epoch045\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03487, dev_eer: 2.232\n",
      "Start training epoch046\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02773, dev_eer: 2.232\n",
      "Start training epoch047\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03140, dev_eer: 2.232\n",
      "Start training epoch048\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03757, dev_eer: 2.232\n",
      "Start training epoch049\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03642, dev_eer: 4.464\n",
      "Start training epoch050\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.04058, dev_eer: 4.464\n",
      "Start training epoch051\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03915, dev_eer: 4.464\n",
      "Start training epoch052\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03833, dev_eer: 4.464\n",
      "Start training epoch053\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02538, dev_eer: 4.464\n",
      "Start training epoch054\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03215, dev_eer: 2.232\n",
      "Start training epoch055\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02534, dev_eer: 2.232\n",
      "Start training epoch056\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02707, dev_eer: 2.232\n",
      "Start training epoch057\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03379, dev_eer: 2.232\n",
      "Start training epoch058\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02483, dev_eer: 2.232\n",
      "Start training epoch059\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01919, dev_eer: 4.464\n",
      "Start training epoch060\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.02469, dev_eer: 4.464\n",
      "Start training epoch061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.01737, dev_eer: 2.232\n",
      "Start training epoch062\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/metrics/dev_score.txt\n",
      "DONE.\n",
      "Loss:0.03257, dev_eer: 0.000\n",
      "best model find at epoch 62\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/eval_scores_libri_libri.txt\n",
      "epoch062, \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(log_text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28mprint\u001b[39m(log_text)\n\u001b[0;32m---> 52\u001b[0m         \u001b[43mf_log\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for swa\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[1;32m     55\u001b[0m optimizer_swa\u001b[38;5;241m.\u001b[39mupdate_swa()\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    print(\"Start training epoch{:03d}\".format(epoch))\n",
    "    running_loss = train_epoch(trn_loader, model, optimizer, device,\n",
    "                               scheduler, config)\n",
    "    produce_evaluation_file(dev_loader, model, device,\n",
    "                            metric_path/\"dev_score.txt\", dev_trial_path)\n",
    "    dev_eer = getEER(metric_path/\"dev_score.txt\")\n",
    "#     , dev_tdcf = calculate_tDCF_EER(\n",
    "#         cm_scores_file=metric_path/\"dev_score.txt\",\n",
    "#         asv_score_file=database_path/config[\"asv_score_path\"],\n",
    "#         output_file=metric_path/\"dev_t-DCF_EER_{}epo.txt\".format(epoch),\n",
    "#         printout=False)\n",
    "    print(\"DONE.\\nLoss:{:.5f}, dev_eer: {:.3f}\".format(\n",
    "        running_loss, dev_eer))\n",
    "    writer.add_scalar(\"loss\", running_loss, epoch)\n",
    "    writer.add_scalar(\"dev_eer\", dev_eer, epoch)\n",
    "#     writer.add_scalar(\"dev_tdcf\", dev_tdcf, epoch)\n",
    "\n",
    "#     best_dev_tdcf = min(dev_tdcf, best_dev_tdcf)\n",
    "    if best_dev_eer >= dev_eer:\n",
    "        print(\"best model find at epoch\", epoch)\n",
    "        best_dev_eer = dev_eer\n",
    "        torch.save(model.state_dict(),\n",
    "                   model_save_path / \"epoch_{}_{:03.3f}.pth\".format(epoch, dev_eer))\n",
    "\n",
    "        # do evaluation whenever best model is renewed\n",
    "        if str_to_bool(config[\"eval_all_best\"]):\n",
    "            produce_evaluation_file(eval_loader, model, device,\n",
    "                                    eval_score_path, eval_trial_path)\n",
    "            dev_eer = getEER(metric_path/\"dev_score.txt\")\n",
    "            eval_eer = getEER(eval_score_path)\n",
    "#             , eval_tdcf = calculate_tDCF_EER(\n",
    "#                 cm_scores_file=eval_score_path,\n",
    "#                 asv_score_file=database_path / config[\"asv_score_path\"],\n",
    "#                 output_file=metric_path /\n",
    "#                 \"t-DCF_EER_{:03d}epo.txt\".format(epoch))\n",
    "\n",
    "            log_text = \"epoch{:03d}, \".format(epoch)\n",
    "            if eval_eer < best_eval_eer:\n",
    "                log_text += \"best eer, {:.4f}%\".format(eval_eer)\n",
    "                best_eval_eer = eval_eer\n",
    "                torch.save(model.state_dict(),\n",
    "                           model_save_path / \"best.pth\")\n",
    "#             if eval_tdcf < best_eval_tdcf:\n",
    "#                 log_text += \"best tdcf, {:.4f}\".format(eval_tdcf)\n",
    "#                 best_eval_tdcf = eval_tdcf\n",
    "#                 torch.save(model.state_dict(),\n",
    "#                            model_save_path / \"best.pth\")\n",
    "            if len(log_text) > 0:\n",
    "                print(log_text)\n",
    "                f_log.write(log_text + \"\\n\")\n",
    "\n",
    "        print(\"Saving epoch {} for swa\".format(epoch))\n",
    "        optimizer_swa.update_swa()\n",
    "        n_swa_update += 1\n",
    "    writer.add_scalar(\"best_dev_eer\", best_dev_eer, epoch)\n",
    "    writer.add_scalar(\"best_dev_tdcf\", best_dev_tdcf, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b329117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start final evaluation\n",
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/eval_scores_libri_libri.txt\n",
      "Exp FIN. EER: 0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Start final evaluation\")\n",
    "epoch += 1\n",
    "if n_swa_update > 0:\n",
    "    optimizer_swa.swap_swa_sgd()\n",
    "    optimizer_swa.bn_update(trn_loader, model, device=device)\n",
    "produce_evaluation_file(eval_loader, model, device, eval_score_path,\n",
    "                        eval_trial_path)\n",
    "eval_eer = getEER(eval_score_path)\n",
    "# , eval_tdcf = calculate_tDCF_EER(cm_scores_file=eval_score_path,\n",
    "#                                          asv_score_file=database_path /\n",
    "#                                          config[\"asv_score_path\"],\n",
    "#                                          output_file=model_tag / \"t-DCF_EER.txt\")\n",
    "f_log = open(model_tag / \"metric_log.txt\", \"a\")\n",
    "f_log.write(\"=\" * 5 + \"\\n\")\n",
    "f_log.write(\"EER: {:.3f}\".format(eval_eer))\n",
    "f_log.close()\n",
    "\n",
    "torch.save(model.state_dict(),\n",
    "           model_save_path / \"swa.pth\")\n",
    "\n",
    "if eval_eer <= best_eval_eer:\n",
    "    best_eval_eer = eval_eer\n",
    "# if eval_tdcf <= best_eval_tdcf:\n",
    "#     best_eval_tdcf = eval_tdcf\n",
    "    torch.save(model.state_dict(),\n",
    "               model_save_path / \"best.pth\")\n",
    "print(\"Exp FIN. EER: {:.3f}\".format(\n",
    "    best_eval_eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f9856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6136fdca",
   "metadata": {},
   "source": [
    "# CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bcfe13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_train_protocol.txt\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/cmu_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU/train/\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/CMU/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "651ce76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "cmu_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c0ec3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv_time): CONV()\n",
       "  (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.5, inplace=True)\n",
       "  (drop_way): Dropout(p=0.2, inplace=True)\n",
       "  (selu): SELU(inplace=True)\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (conv1): Conv2d(1, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(32, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(24, 24, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (mp): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (GAT_layer_S): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (GAT_layer_T): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST11): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_type2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (att_proj): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST12): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST21): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (proj_type2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (att_proj): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=24, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST22): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (pool_S): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=24, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_T): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=24, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (out_layer): Linear(in_features=160, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eaf7d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/LIBRI_AASIST-L_ep100_bs24/eval_scores_libri_cmu.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc9b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cc7cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in cmu_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "268329ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU EER:  37.77777777777778\n"
     ]
    }
   ],
   "source": [
    "eer_cmu = getEER(eval_score_path)\n",
    "print('CMU EER: ', eer_cmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd91615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72d3df6e",
   "metadata": {},
   "source": [
    "# LJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5599479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataset partitions\n",
    "SET_PARTITION = [\"trn\", \"eval\"]\n",
    "\n",
    "# list of countermeasure(CM) protocols\n",
    "SET_CM_PROTOCOL = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/lj_train_protocol.txt\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/protocols/lj_test_protocol.txt\",\n",
    "}\n",
    "\n",
    "# directories of each dataset partition\n",
    "SET_DIR = {\n",
    "    \"trn\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/LJ/train/\",\n",
    "    \"eval\": \"/DATA/nfsshare/rishith/datasets/smaller_dbs/restructured/LJ/test/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6bc7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "meta_lines = open(SET_CM_PROTOCOL[\"eval\"], \"r\").readlines()\n",
    "utt_list = []\n",
    "for line in meta_lines:\n",
    "    tmp = line.strip().split(\" \")\n",
    "\n",
    "    utt = tmp[0]\n",
    "    utt_list.append(utt)\n",
    "\n",
    "base_dir = SET_DIR['eval']\n",
    "dataset = Dataset_PrevDbs(utt_list, Path(base_dir))\n",
    "lj_loader = DataLoader(\n",
    "        dataset, batch_size=24, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd18bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/LIBRI_AASIST-L_ep100_bs24/eval_scores_libri_lj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3805c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_path = SET_CM_PROTOCOL['eval']\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in lj_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        utt_id, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76294b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lj EER:  30.612244897959183\n"
     ]
    }
   ],
   "source": [
    "eer_lj = getEER(eval_score_path)\n",
    "print('Lj EER: ', eer_lj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc7130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c565ec",
   "metadata": {},
   "source": [
    "# ASVspoof 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e50221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_trial_path = Path('/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt')\n",
    "eval_database_path = Path('/DATA/nfsshare/rishith/datasets/asvSpoof2019/DS_10283_3336/LA/ASVspoof2019_LA_eval/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35480805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSpoof_list1(dir_meta, is_train=False, is_eval=False):\n",
    "\n",
    "    d_meta = {}\n",
    "    file_list = []\n",
    "    with open(dir_meta, \"r\") as f:\n",
    "        l_meta = f.readlines()\n",
    "\n",
    "    if is_train:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list\n",
    "\n",
    "    elif is_eval:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, _ = line.strip().split(\" \")\n",
    "            #key = line.strip()\n",
    "            file_list.append(key)\n",
    "        return file_list\n",
    "    else:\n",
    "        for line in l_meta:\n",
    "            _, key, _, _, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34e55a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_eval = genSpoof_list1(dir_meta=eval_trial_path,\n",
    "                          is_train=False,\n",
    "                          is_eval=True)\n",
    "eval_set = Dataset_ASVspoof2019_devNeval(list_IDs=file_eval,\n",
    "                                         base_dir=eval_database_path)\n",
    "eval_loader = DataLoader(eval_set,\n",
    "                         batch_size=config[\"batch_size\"],\n",
    "                         shuffle=False,\n",
    "                         drop_last=False,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81deedf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0009, 0.0008, 0.0007,  ..., 0.1776, 0.1562, 0.1233]),\n",
       " 'LA_E_2834763')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bf09fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score_path = Path('exp_result/LIBRI_AASIST-L_ep100_bs24/eval_scores_libri_asv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cd25c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/eval_scores_libri_asv\n"
     ]
    }
   ],
   "source": [
    "trial_path = eval_trial_path\n",
    "with open(trial_path, \"r\") as f_trl:\n",
    "    trial_lines = f_trl.readlines()\n",
    "fname_list = []\n",
    "score_list = []\n",
    "for batch_x, utt_id in eval_loader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    with torch.no_grad():\n",
    "        _, batch_out = model(batch_x)\n",
    "        batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "    # add outputs\n",
    "    fname_list.extend(utt_id)\n",
    "    score_list.extend(batch_score.tolist())   \n",
    "assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "\n",
    "with open(eval_score_path, \"w\") as fh:\n",
    "    for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "        _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "        assert fn == utt_id\n",
    "        fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "print(\"Scores saved to {}\".format(eval_score_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7035df9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_lines) == len(fname_list) == len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef7d6c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71237\n",
      "71237\n",
      "71237\n"
     ]
    }
   ],
   "source": [
    "print(len(trial_lines))\n",
    "print(len(fname_list))\n",
    "print(len(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d5fb7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEER1(score_path):\n",
    "    cm_data = np.genfromtxt(score_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 2]\n",
    "    cm_scores = cm_data[:, 3].astype(float)\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "    return eer_cm * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5efc93a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASV EER:  50.98595864558318\n"
     ]
    }
   ],
   "source": [
    "eer_asv = getEER1(eval_score_path)\n",
    "print('ASV EER: ', eer_asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97dcd50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df713950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores saved to exp_result/LIBRI_AASIST-L_ep100_bs24/eval_scores_libri_asv\n"
     ]
    }
   ],
   "source": [
    "produce_evaluation_file(eval_loader, model, device, eval_score_path,\n",
    "                            eval_trial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5e3d088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASV EER:  50.98595864558318\n"
     ]
    }
   ],
   "source": [
    "eer_asv = getEER1(eval_score_path)\n",
    "print('ASV EER: ', eer_asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faff371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
